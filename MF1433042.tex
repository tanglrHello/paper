%% 使用 njuthesis 文档类生成南京大学学位论文的示例文档
%%
%% 作者：胡海星，starfish (at) gmail (dot) com
%% 项目主页: http://haixing-hu.github.io/nju-thesis/
%%
%% 本样例文档中用到了吕琦同学的博士论文的提高和部分内容，在此对他表示感谢。
%%
\documentclass[master, winfont]{njuthesis}
%% njuthesis 文档类的可选参数有：
%%   nobackinfo 取消封二页导师签名信息。注意，按照南大的规定，是需要签名页的。
%%   phd/master/bachelor 选择博士/硕士/学士论文

% 使用 blindtext 宏包自动生成章节文字
% 这仅仅是用于生成样例文档，正式论文中一般用不到该宏包
\usepackage[math]{blindtext}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{ulem}
\usepackage{multirow}
\usepackage{tikz}
\usepackage{array}
\usepackage{xfrac}
\usetikzlibrary{shapes,arrows}
%\setlength\titlebox{5cm}
\renewcommand{\algorithmicrequire}{ 输入:} %Use Input in the format of Algorithm
\renewcommand{\algorithmicensure}{ 输出:} %UseOutput in the format of Algorithm
\floatname{algorithm}{算法}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 设置《国家图书馆封面》的内容，仅博士论文才需要填写

% 设置论文按照《中国图书资料分类法》的分类编号
%\classification{0175.2}
% 论文的密级。需按照GB/T 7156-2003标准进行设置。预定义的值包括：
% - \openlevel，表示公开级：此级别的文献可在国内外发行和交换。
% - \controllevel，表示限制级：此级别的文献内容不涉及国家秘密，但在一定时间内
%   限制其交流和使用范围。
% - \confidentiallevel，表示秘密级：此级别的文献内容涉及一般国家秘密。
% - \clasifiedlevel，表示机密级：此级别的文献内容涉及重要的国家秘密 。
% - \mostconfidentiallevel，表示绝密级：此级别的文献内容涉及最重要的国家秘密。
% 此属性可选，默认为\openlevel，即公开级。
%\securitylevel{\controllevel}
% 设置论文按照《国际十进分类法UDC》的分类编号
% 该编号可在下述网址查询：http://www.udcc.org/udcsummary/php/index.php?lang=chi
%\udc{004.72}
% 国家图书馆封面上的论文标题第一行，不可换行。此属性可选，默认值为通过\title设置的标题。
%\nlctitlea{数据中心}
% 国家图书馆封面上的论文标题第二行，不可换行。此属性可选，默认值为空白。
%\nlctitleb{网络模型研究}
% 国家图书馆封面上的论文标题第三行，不可换行。此属性可选，默认值为空白。
%\nlctitlec{}
% 导师的单位名称及地址
%\supervisorinfo{南京大学计算机科学与技术系~~南京市汉口路22号~~210093}
% 答辩委员会主席
%\chairman{张三丰~~教授}
% 第一位评阅人
%\reviewera{阳顶天~~教授}
% 第二位评阅人
%\reviewerb{张无忌~~副教授}
% 第三位评阅人
%\reviewerc{黄裳~~教授}
% 第四位评阅人
%\reviewerd{郭靖~~研究员}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 设置论文的中文封面

% 论文标题，不可换行
\title{基于中文地理试题的AMR研究}
% 论文作者姓名
\author{汤莲瑞}
% 论文作者联系电话
\telphone{}
% 论文作者电子邮件地址
\email{tanglr@nlp.nju.edu.cn}
% 论文作者学生证号
\studentnum{MF1433042}
% 论文作者入学年份（年级）
\grade{2014}
% 导师姓名职称
\supervisor{戴新宇~副教授}
% 导师的联系电话
\supervisortelphone{}
% 论文作者的学科与专业方向
\major{计算机技术}
% 论文作者的研究方向
\researchfield{自然语言处理}
% 论文作者所在院系的中文名称
\department{计算机科学与技术系}
% 论文作者所在学校或机构的名称。此属性可选，默认值为``南京大学''。
\institute{南京大学}
% 论文的提交日期，需设置年、月、日。
\submitdate{2017年5月20日}
% 论文的答辩日期，需设置年、月、日。
\defenddate{2017年5月30日}
% 论文的定稿日期，需设置年、月、日。此属性可选，默认值为最后一次编译时的日期，精确到日。
\date{2017年5月20日}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 设置论文的英文封面

% 论文的英文标题，不可换行
\englishtitle{Research on Interactive Phrase-based Machine Translation}
% 论文作者姓名的拼音
%\englishauthor{}
\englishauthor{Lianrui Tang}
% 导师姓名职称的英文
%\englishsupervisor{}
\englishsupervisor{Vice Professor Xinyu Dai}
% 论文作者学科与专业的英文名
\englishmajor{Computer Technology}
%\englishmajor{Computer Technology}
% 论文作者所在院系的英文名称
\englishdepartment{Department of Computer Science and Technology}
% 论文作者所在学校或机构的英文名称。此属性可选，默认值为``Nanjing University''。
\englishinstitute{Nanjing University}
% 论文完成日期的英文形式，它将出现在英文封面下方。需设置年、月、日。日期格式使用美国的日期
% 格式，即``Month day, year''，其中``Month''为月份的英文名全称，首字母大写；``day''为
% 该月中日期的阿拉伯数字表示；``year''为年份的四位阿拉伯数字表示。此属性可选，默认值为最后
% 一次编译时的日期。
\englishdate{May 20, 2017}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 设置论文的中文摘要

% 设置中文摘要页面的论文标题及副标题的第一行。
% 此属性可选，其默认值为使用|\title|命令所设置的论文标题
% \abstracttitlea{数据中心网络模型研究}
% 设置中文摘要页面的论文标题及副标题的第二行。
% 此属性可选，其默认值为空白
% \abstracttitleb{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 设置论文的英文摘要

% 设置英文摘要页面的论文标题及副标题的第一行。
% 此属性可选，其默认值为使用|\englishtitle|命令所设置的论文标题
\englishabstracttitlea{Research on Interactive Phrase-based Machine Translation}
% 设置英文摘要页面的论文标题及副标题的第二行。
% 此属性可选，其默认值为空白
\englishabstracttitleb{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% 制作国家图书馆封面（博士学位论文才需要）
%\makenlctitle
% 制作中文封面
\maketitle
% 制作英文封面
\makeenglishtitle


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 开始前言部分
\frontmatter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 论文的中文摘要
\begin{abstract}
人工智能技术正在飞速改变这个世界。在自然语言领域，围绕着自动问答系统(QA)也开展了越来越多的研究。高效、智能的问答系统，致力于为使用者直接提供更直接和更优质的答案，可以自动从大量的知识储备中进行检索、推理，从而将使用者从海量信息的搜索、筛选、抽取答案的过程中解放出来。2011年，IBM的Watson问答机器人参加问答类综艺节目“Jeopardy!”，并战胜了人类顶尖选手赢得冠军，自动问答系统再一次吸引了世人的眼光。

从某种程度上来说，高考作为中国大多数中学生最重要的考试，可以看做高水平的问答过程。本文的项目背景是面向中国高考地理试题的问答系统，并专注于对选择题的解答。在解决高考自动问答的过程中，我们面临多项挑战：首先高考题的问答形式与传统自动问答系统的问题存在明显区别；其次，高考题的灵活性远高于传统问答系统处理的问题，这意味着我们很难从现成的文本中直接匹配、抽取得到答案，所以在解题过程中，我们面临着与传统问答系统不同的挑战。

作为问答系统的第一步处理，问题理解的作用举足轻重。本文重点关注在地理选择题的问题理解过程。本文主要从两个方面来研究对于地理试题的理解问题：一方面是句子分割的浅层处理，另一方面是使用AMR对试题文本进行深层处理。

我们针对地理选择题的特点，提出了利用逗号对选择题的选项进行拆分，将较长的原句转换成语义等价的多个简单句，从而简化后续的处理步骤的输入，提高后续步骤的处理能力。在这项工作中，我们使用了最大熵分类器和一些基于规则的启发式方法，通过一个两步骤的方法来实现句子拆分：首先识别选项中的逗号是否可以作为一个分割点，然后在识别句子的从句或并列结构的公共前缀边界。

AMR（Abstract Meaning Representation）是一种具有较为强大的表达能力的的新型语义表示方法，它可以将一句话的语义用单根的、有向的连通图表示出来，更强调句子的抽象语义，而非具象的语法表达方式。但是由于围绕AMR的研究才刚刚起步，目前已有的AMR自动分析效果仍然还有很大待提升的空间。中文AMR的标注语料仍未达到一定规模，尚在进展中，所以关于AMR的中文应用研究几乎还是空白。本文在AMR方面工作主要是对现有AMR分析算法进行一些实验分析，并首次验证AMR标注体系及自动解析算法在中文上的性能。针对地理试题，我们标注了一个小样本的AMR语料，并用现有算法来验证AMR在特定领域文本上的处理能力。

为了支撑上述两项问题理解的研究工作，我们还构建了一个地理试题标注工具，并通过这个工具建立一个高质量的地理试题语料库。除了可以标注句子分割和AMR这两种信息，该工具同时支持标注分词、词性、命名实体、地理术语、试题模板表示、成分句法等各项数据。

\keywords{问题理解；句子拆分；语义分析；AMR；地理文本；标注工具；}
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 论文的英文摘要
\begin{englishabstract}
Artificial intelligence is changing the world rapidly. Recent years, more and more research on automatic question-answering is carried out in the field of natural language process. A highly efficient and intelligent QA system aims to provide more direct answers to users with high quality, which can retrieve information from large-scale knowledge and make deductions automatically. Therefore, it free users from searching, filtering texts from the large quantity of information, as well as finally extracting the answers by themselves. In 2011, the QA robot Watson from IBM took part in a quiz show named Jeopardy! on TV, beat the top human players and became the champion. Once again, QA system attracted the attention of the world.

To some extent, the college entrance examination is the most importance examination for almost all the Chinese middle school student, which can be seemed as a high-level question answering situation. The background of this paper is a question answering system focused on the geography part of the Chinese college entrance examination. And we paid more attention to answering the choice questions of test paper.  In the process of accomplishing the QA system for college entrance examination, we are faced with many challenges. Firstly, the question form is different from those for traditional QA systems. Secondly, the questions are much more flexible, which means we can hardly match the question to the original texts in the knowledge base directly. Therefore, the answer extraction is harder. We need to rely on automatic inference to generate answer from the those texts.

As the first stage of automatic question-answering, question comprehension plays a key role for the whole system. This paper focuses mainly on some issues on the understanding of geography choice questions. AMR(Abstract Meaning Representation) is a new and powerful semantic representation for sentences. In this paper, we parse the Chinese sentences into AMR. As far as we know, this is the first work about Chinese AMR parsing. Then we tried to apply AMR on the understanding of geography questions. Besides, in order to research the performance of a variety of natural language processing tasks on geography question data, we build a tool for tagging various data on question texts, including question splitting, Chinese word segmentation, part-of-speech, named entities, geographical terms, template representation for questions, syntactic tree, and AMR. According to the feature of choice questions, we present a question simplification approach, which splitting a composed sentence into multiple simple sentences by commas. In this way, we can simplify the input for the following processing stages.

The research on AMR has just started. The performance of state-of-the-art approaches for parsing English sentences into AMR is still not satisfactory. Besides, the size of Chinese AMR corpus is relatively small. Some AMR corpus annotation work is still in progress. So there is almost no work about Chinese AMR. The work in this paper about AMR is very preliminary. And we just do some exploration to apply AMR to question understanding.

% 英文关键词。关键词之间用英文半角逗号隔开，末尾无符号。
\englishkeywords{Question Comprehension, Semantic Parsing, AMR, Geographic Text, Annotation Tool, Sentence simplification}
\end{englishabstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 论文的前言，应放在目录之前，中英文摘要之后
%
%\begin{preface}
%\section{研究背景}
%想
%\vspace{1cm}
%\begin{flushright}
%程善伯\\
%2013年夏于南京大学
%\end{flushright}
%
%\end{preface}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 生成论文目次
\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 生成插图清单。如无需插图清单则可注释掉下述语句。
\listoffigures

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 生成附表清单。如无需附表清单则可注释掉下述语句。
\listoftables

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 开始正文部分
\mainmatter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 学位论文的正文应以《绪论》作为第一章
\chapter{绪论}\label{chapter_introduction}
\section{研究背景}
在人工智能技术日新月异的今天，人们对人工智能技术寄予了越来越多的期待。在各个领域，人们都在不断试图突破人工智能目前的极限。在自动问答领域，已经有很多商业化的系统为企业提供高效的解决方案，为用户提供更加快捷、准确的服务。在自动问答出现以前，我们获取知识的方式通常是在搜索引擎中搜索关键字，在得到的网页文本中一个个去搜寻是否包含了我们想要的答案。问答系统的出现是对搜索引擎功能的一次升级。问答系统希望不但能够从海量数据中找到与用户问题相关的文本，还能够从文本中直接准确地找出答案，免去使用者自己去从搜索结果中进一步寻找答案的过程。

通常我们所说问答系统可以针对一个自然语言的问句，在知识库中找到相关的支持文本，然后可能涉及到一些简单的推理，接着抽取出可能的答案，再对所有答案进行综合打分，并将最终的答案返回给用户。waston系统是这类问答系统的一个变种，输入是一个陈述句，但是可能其中的一个命名实体或者时间被代词替代，waston所做的事情就是首先识别出哪个代词是需要消解出来的，然后进行上述的问答系统的流程\cite{Ferrucci2010}。

从某种角度来说，考试的过程就是一种问答过程，而高考作为中国学生进入高等教育的关键考试，其试题更具有难度和代表性，高考是对考试者的知识积累、推理能力、判断能力的一种综合考察。为了探索问答系统的潜力，基于863项目《开放域知识集成、推理与检索关键技术及系统》，我们对地理试题的自动解答进行了研究。在高考地理试题中，选择题是一类重要的题型。不同于传统的问答系统，选择题不是一个有明确疑问词的疑问句，也不像waston那样去消解一个句子中未知的代词。选择题更像是对四个选项的陈述做出判断的判断题。并且我们很难直接从课本或者其他文本中直接得到相关文本，通过匹配来判断一个句子是否正确，而是需要根据上下文的时间、地点、假设等等，综合相关的知识点，经过复杂的推理和计算才能够得到正确答案，因此和传统的问答系统存在很大区别。

在试题自动解答的过程中，对问题的理解是一个关键步骤。这一步包括对问题做各种基础的自然语言处理，得到一些基本的分析结果。对每一项基础分析任务，我们需要针对地理领域试题的特点，做出一些针对性的调整，提高通用工具对地理试题的处理能力。在本文中，主要从句子拆分简化和AMR语义表示解析两方面来研究试题理解问题。对于地理选择题的特点，我们提出了基于选项中的逗号对句子进行拆分简化的方法。另外，针对句子的理解，除了目前比较常见的语义角色标注等语义分析方法，我们还尝试使用了近些年新提出的AMR方法，这个表示体系对于句子语义有更强的表示能力，也是一种比较值得探索的新方向，因此本文也基于目前已有的研究，对AMR在中英文语义表示和自动分析方面做了一些实验分析，探索AMR目前可以达到的水准，并在一个小的地理领域试题数据上进行了实验，希望能够为后面的问题理解工作探索一个新思路。

\section{中文句子分割的研究现状}
\label{section:imtnow}
逗号是一种十分常见的标点符号，在中文文本中，逗号出现的频率比英文等语言更高，据统计每个英文句子中平均有0.869~1.04个逗号，而每个中文句子中平均有1.79个逗号\cite{Jin2004}。在中文的长句子分析中，逗号可以起到十分重要的作用。在中文中，逗号不仅仅可以作为一个句子内部从句或者短语之间的停顿符号\cite{Li2004}，也可以作为两个句法独立的句子之间的分割符\cite{Xu2013}\cite{Xue2011}。所以对于包含逗号的中文长句来说，利用逗号来将长句分解成更短的句子，可以对很多自然语言处理任务有比较好的提升作用，例如机器翻译\cite{Wang2014}、句法分析\cite{Jin2004}\cite{2007}\cite{Kong2014}\cite{Li2004}\cite{Li2008}等等。

Mei等人\cite{Jin2004}在文章中指出，中文的逗号中，约有30\%是用来将从句与主句或相邻的从句之间分隔开。文中指出逗号是一个中文句子的自然分割点，可以将逗号分割和句法分析结合起来，首先在合适的逗号位置将句子切分成几个短句，然后对每个短句分别做依存句法分析，再将短句对之间用一个依存关系连接起来，得到原长句的句法分析结果。不是所有的逗号都可以作为这样的分割点，有些逗号如果做为分割点，会导致一些词在短句内找不到head词，还有会导致一些词找到错误的head词。作者提出的方法认为，如果逗号分割的两个短句之间只存在一条依存关系边，则认为这个逗号是合理的分割点，通常这样的逗号出现在一个从句结束的地方。文章对每个逗号抽取了一些特征，使用SVM分类器对从句内逗号和从句间逗号进行分类，获得了87.1\%的准确率，并且显示可以使依存句法分析的性能提升9.6\%。

Xing Li等人\cite{Li2004}将标点符号看为分割标点和普通标点两种，前者可以将一个句子分割成几个子句。文章中主要使用了基于规则的方法来处理长句的句法分析。将句法分析分解成一个两步句法分析方法：首先用所有冒号、逗号、分好，将句子分成多个子句；然后第一步先对分割出的子句进行句法分析；再使用一种基于句法分析结果的规则的方法，判断出每个逗号是否分割一个并列结构，而不是多个从句，如果出现这种情况再使用规则的方法将这几个子句的句法树合并起来；最后在将每个子树的根节点的词性标签序列作为句法分析的输入，再做第二次parsing，结合前面的子树结果就可以得到原句完整的句法树。实验结果证明这种方法可以有效缩短长句句法分析的时间，并且可以将句法分析的性能提升7\%。

毛奇等人\cite{2007}为了处理句法分析中的长句问题，提出了单独解析块的概念，指由特定的标点符号分割句子生成的自然次序列。单独解析块又分为可单独解析块和不可单独解析块，区别在于，前者的内部词序列在正确的句法树中只有一个根节点。文章思想类似Xing Li等人\cite{Li2004}的工作，但是由于使用规则的方法能够处理的情况比较局限，他们提出了一种基于统计的方法。因此将逗号分类的任务形式化为了对可单独解析块的识别问题。文中考虑了包括逗号在内的五种标点符号作为单独解析块的划分边界，提出一个特征集合，并使用了Id3决策树分类算法进行分类，对于可单独解析块的识别F值可以达到85.1\%，对不可单独解析块的识别F值为69.7\%。然后将单独解析块的识别加入句法分析的过程，首先对所有的可单独解析块进行句法分析，得到一个子树结构，然后在这些子树中抽取出其中的中心词与词性，再将这些中心词与其他不可单独解析块合并成一个词与词性序列，在对这个组合序列进行句法分析得到一颗全局句法树，最后再将之前得到的子树结构整合进最终的句法树中。实验结果表明，这种方法可以使句法分析效果在长度大于40的长句中，准确率提高1.59\%，召回率提高0.93\%，并且该方法有效缩短了句法分析花费的时间。

Jinhui Li等人\cite{Li2008}提出了另一种可以处理中英文句子的层次化句法分析的方法。文章从句法树森林中递归地识别出简单的组成成分，然后逐步减小句法树森林中句法树片段的个数，直至全部合并为一棵句法树。总体上大致分为三个步骤：词性标注、组块分析、句法分析。算法从由所有组块的句法树组成的森林开始，并且设计了一个BIESO标签体系，每一次句法树合并之前，都会使用最大熵模型从左到右地预测出每一棵子树的标签，然后对能够合并的连续子树进行合并，得到新的更小的句法树森林。这篇文章虽然并未直接涉及到利用逗号来作为句子的分割点，但是在组块分析中，实际上也用到了逗号的信息。

李艳翠\cite{liyancui2015}在研究中文篇章关系的工作中，从基本篇章单位的角度，对标点符号进行分类，分成篇章单位间标点和篇章单位内标点，其中篇章间标点中，逗号就占到了61.3\%。Yang Y.Q.等人\cite{Yang2012Chinese}对逗号的作用主要分为了表明并列关系和从属关系的两类。其中表明并列关系的逗号包括三种：起到句子边界作用的逗号、分割父节点为非根节点的并列IP结构的逗号、分割并列动宾短语的逗号。另一种表明从属关系的分为三类：分割附属从句与主句的逗号、分割句子谓语与宾语的逗号、分割句子主语和谓语的逗号。这里更多地从语法功能的角度对逗号的作用进行了划分，而不是像上面的一些工作，完全从句法树的角度来对逗号进行分类。

总的来说，对中文长句中的逗号进行句子切分，并没有一个十分明确的标准，有些研究是从句法树的角度出发，认为逗号是否能够切分句子，取决于人工标注的句法树是否将逗号前后两个部分表示成独立的子树；有些则是先在所有逗号处进行切分，再根据并列结构等的句法特点，识别出不应作为切分点的逗号并修正；还有些是从逗号在篇章切分中的作用出发，结合句法特点来对逗号进行分类。如何利用逗号来得到更简短的句子，要考虑到切分结果对某种应用场景（比如句法分析）的作用，也就是明确切分的目的是为了什么，并结合所处理的语料特点，选择合适的分类标准，从而用逗号将长句切分成短句。

\section{AMR的研究现状}
句法树库对自然语言处理领域的发展具有巨大的影响力，比如宾州树库就是一个典型的例子。但是在语义标注方面，目前已有的标注语料还比较分散，比如有单独的命名实体、指代消解、语义关系、篇章关系等等，目前还缺少一个能够将整个句子的语义逻辑关系组合在一起的语义标注树库。AMR就是在这样的背景下被提出的，这是一种能够将句子语义表示成一个简单有向图的的表示方法，在这个有向图中，节点表示一个概念，通常是句子中的一个词语或者词组，或者在词语或词组的基础上抽象出来的概念，有向边表示节点之间的关系，边具有指示概念间语义关系的标签。这种表示体系的提出，以及基于这个体系的语料库的建立，可能会给自然语言理解的任务带来新的发展空间。

AMR表示是一种由单个根节点的、有标注图的表示方法\cite{Banarescu2013Abstract}，对人来说，AMR标注是易读的，同时对于程序来说，也很容易获取到该表示中的所有信息。AMR的目标是能够从句子的不同的句法表达方式中，抽象出句子的语义，也就是说对于不同表达方式的同一个语义的句子，希望能够得到相同的AMR表示结果。在AMR表示中，用到了大量PropBank框架的内容，对具有多个表示框架的谓词，会在概念节点中注明对应的是该谓词的哪种用法，在标注它的论元时，也会在边上标记出相应的论文序号。

L Banarescu等人\cite{banarescu2012abstract}在2012年提出了第一个版本的AMR标注规范，明确了AMR应该如何标注，并给出了大量的标注实例，说明了怎么选择根节点、节点的内容应该怎样确定、关系标签的几种类型、常见句式中如何添加新的抽象节点和标注关系标签、如何标注命名实体和数字时间及其它各类型实体等等。在这个标注规范的基础上，L Banarescu等人\cite{Banarescu2013Abstract}在2013年公布了一个英文的AMR标注图库，包含大约5000句标注文本。

在中文方面，李斌等\cite{Li2016Annotating}在《小王子》文本上标注了一个AMR图库，总共包含1562个句子，并且据悉，一个规模超过5000句的AMR图库正在标注过程中。中文的语法表达比英文更加随意，例如有时会出现一个谓词在句子中不是连续的字序列，而是被别的词语分割开来（例如“帮了很大的忙”中的谓词“帮忙”）。文中对一些中文AMR标注中特殊之处进行了详细说明，成为AMR在中文中的应用的一个开创性的工作。此外，在英文的AMR标注中，没有标注图中的概念节点与原句中的词语的对齐关系，通常都是借助自动对齐算法来进行对齐，因此可能会损失一定的精度。在这项中文AMR标注工作中，还加入了对齐信息的标注，包括概念节点的对齐以及少部分边的对齐信息。

有了AMR语料库之后，陆续出现了一些AMR自动解析的算法。最早的公开工作是来自Flanigan等人\cite{Flanigan2014}在2014年提出的一种两阶段的图算法，将AMR解析分成概念节点识别和概念节点间的边预测两个步骤，对于边的预测，采用了一种类似最大生成树算法的方式，得到所有概念节点间相互连接形成的连通图。\cite{Angeli2014}对于AMR子图的生成提出了一种鲁棒性更强的方法。随后在2015年，Wang Chuan\cite{Wang2015}等人发现AMR的表示方法有一部分与句法分析的结果比较相似，受到基于转换的句法分析算法的启发，他们提出了一种基于转换的AMR解析算法，并设计了一套使用于AMR图生成的转换方法：在句子的依存句法分析结果的基础上，每次预测一种转换动作，一步步将句法分析的结果转换成AMR的表示。Pust等人\cite{Pust2015}于同年提出了使用基于语法的机器翻译的方法来做AMR的解析，这篇研究将英文句子到AMR表示的转换看成是一种string到tree的翻译过程，并设计了一种AMR表示下的语言模型。Lucy Vanderwende等人\cite{Vanderwende2015}的工作则支持对英文、法文、德文、西班牙文、日文的AMR解析，他们设计了一些逻辑形式（Logical Form）到AMR的转换规则，通过这样的方法来实现对上述语言的解析，这些语言还没有可用的AMR语料库，所以这篇文章对于AMR在其他语言中的扩展也有重要的借鉴意义。

AMR作为一种语义表示方法，被寄希望于提高多项nlp任务的性能，目前已发表的研究中，有将AMR用于提高事件检测任务的性能\cite{kai2015improving}，Xiang Li等人利用现有的性能最好的AMR自动分析算法，对待检测事件的文件进行AMR解析，然后将AMR结果中的一些数据作为特征加入，实验结果证明这样的做法可以在原来的基础上提高2.1\%的F值。还有研究将AMR用于无监督的实体链接任务\cite{Pan2015}，结果表明使用了AMR信息的无监督实体链接的性能可以和有监督的实体链接性能相当。

目前已知的AMR英文语料规模达到了4万多句，中文的大规模语料库预计也将于不久之后公开，随着更多可用语料的出现，对AMR自动解析和将AMR应用于其他自然语言处理任务的研究会越来越多，因此AMR是一种具有潜力的语义表示方法，尽管目前在中英文上的AMR自动解析效果还不尽如人意，但是AMR的出现为语义分析和自然语言理解提供了一个全新的研究方向。

\section{论文的主要工作}
本文工作主要是关于地理试题文本的问题理解，具体是从下面三个主要方面开展工作：

其一，针对选择题选项的特点，我们提出对部分含有逗号的选项进行句子简化拆分。我们发现地理选择题中有14\%的选项中包含一个或一个以上的逗号，在这些包含逗号的选项中，有71.7\%的选项，可以通过在某处寻找一个边界，将句子分割成公共部分和非公共部分，然后组合成多个可以分别判断正误的句子。虽然这部分可拆分的选项在我们标注的所有数据中只占10.1\%，但是根据我们在后续试题语义模板化处理的过程中发现，对于这类句子的处理难度较大，较严重影响地影响了自动模板化的性能，因此对这部分的简化拆分是一个重要的步骤。

其二，探索AMR在中英文语义分析上的效果，及其在地理试题上的应用效果。AMR是一种新型的语义表示方式，在此之前，我们在高考问答系统中使用的主要语义分析方法，是将试题文本通过其句法结构和词性等特征，转换为一个我们制定的地理试题模板体系，每个模板根据其定义包括模板类型和语义槽，每个选择题和问答题的核心问题部分都可以转换成一个语义模板的表达。经调研发现，AMR的表示体系中有很多类似的语义结构，如果针对地理文本对某些关键的实体和关系进行AMR的解析，在理想的效果下可以方便地转换为我们所需要的模板表达方式。所以我们探索了AMR当前的表达和自动分析能力，并尝试将其应用在地理试题上。

其三，为了支撑上述两项围绕问题理解的研究，我们需要构建一个地理试题的语料库，为此开发了地理试题标注系统。由于研究开始时缺乏足够的有标注地理文本，我们针对地理试题的结构特点，包括文本外部组织结构和文本内部的语法表达方式，设计并开发了一个标注系统，该系统支持特定格式的试卷导入，同时支持选择题和主观题的试卷格式，能够保留试卷原有的结构信息（比如高考题常有一些几道连续的题目共享的背景知识，主观题大题小题的嵌套，地理试题的主选项和小选项等等），支持对包括分词、词性、命名实体、术语、语义模板表示、成分句法分析、选择题主次文本、AMR的标注。可以通过关键字、试卷名、某一项数据的标注状态、模板类型等多种方式进行试题检索，可以对所有标注内容导出成文本文件，提高了地理试题的标注效率和标注数据的检索和使用效率。

通过上述工作，我们建立了一个包含多项标注结果的地理试题语料，并为试题理解提供了更加简单的输入文本。另外实验结果表明，目前已有的AMR自动解析方法在中文上的性能还明显低于英文，。。。。。

\section{论文的组织}
本文内容的组织如下：

第一章主要介绍本文研究内容的背景，以及论文主要工作内容，并简述了本文围绕地理试题理解的两个主要研究工作的相关进展，一方面是基于逗号的句子拆分的研究现状，另一方面是关于AMR语义表示体系的研究现状。

第二章主要介绍本文提出的基于逗号对选择题选项进行拆分简化的工作。首先会介绍基于逗号的句子分解的相关工作，然后阐述本文工作的内容。阐明做选项拆分的动机，详细说明如何在问题理解分析中对选择题选项文本进行分割，主要分为两个步骤，第一步是判断句子是否可拆分，第二步是寻找到拆分的边界，类似补全句子成分的步骤。本章同时描述了我们选取的文本特征和算法，给出当前的实验结果，以及错误分析。

第三章主要介绍对AMR在中英文语义理解上的相关内容。首先介绍目前AMR的研究进展，包括标注体系及规范，语料建设情况，自动解析算法等内容。对于这个较新的任务，我们使用了目前性能比较领先的一种图算法，对多种中英文语料设计了多种实验，对标注数据和算法流程进行了阐述，并在少量地理题标注数据上做了实验，为后续AMR相关的工作提供参考。并总结JAMR对于中文AMR解析的问题，以及目前存在的一些缺陷。

第四章主要介绍地理试题标注系统的相关内容。主要包括系统架构、功能设计、数据库设计、交互方式等各个方面，以及目前通过该系统完成标注的地理语料规模，以及语料的数据统计结果等。

第五章主要是对本文工作的总结以及对未来工作的展望。

\chapter{背景知识}
\section{引言}


本章是本文主要工作展开的基础。本文对于高考地理试题中的问题理解主要从两方面展开：一方面是逗号在句子分割简化中的作用，由此将长句拆解成多个等价的短句，降低问题理解的难度；另一方面是考虑从新型的语义表示方法AMR出发，对问题的深层语义进行解析。所以本文的背景知识由两方面组成，一方面是关于逗号在中文长句中的作用及相关研究进展，另一方面是AMR的知识体系及研究进展。

对于逗号相关的中文长句处理，我们主要介绍中文中逗号的功能分类体系；对于AMR，我们将从AMR表示体系的定义、标注体系、语料建设、自动对齐、自动解析算法、自动评价等方面详细介绍。通过对以上内容的分析介绍，可以对本文的工作有更清晰的认识，也为我们的工作打下了基础。


\section{本章小结}
本章主要介绍了基于短语的统计机器翻译系统的各部分重点内容。首先介绍了短语机器翻译的整体框架与流程。在此基础上，分别介绍了短语机器翻译的建模方法，参数训练方法，解码方法等内容。

短语翻译系统通过最小错误率训练进行对数线性模型的参数调节，在开发集上，直接对翻译评价指标进行参数调节，每次调节一维参数，经过多轮迭代获得最优参数。统计机器翻译最常用的自动评价指标为BLEU。

短语翻译系统采用了对数线性模型进行建模，可以自然地使用各种特征。短语翻译系统主要使用了翻译概率、词汇化调序概率、语言模型概率、词计数、短语计数等特征。为了减少搜索空间，降低搜索复杂度，短语翻译系统采用了一种启发式搜索算法：柱搜索解码算法。柱搜索算法通过源端词数维护搜索栈，即翻译了相同源端词数的假设置于同一个栈中。柱搜索算法的核心是假设扩展和假设剪枝。翻译系统通过将翻译选项的目标端连接到局部假设之后，并同时更新假设的各项特征值来进行假设扩展。翻译系统通过局部假设的特征值得分和未来代价估计相加进行局部假设的得分估计，并使用该得分估计进行剪枝，提高了局部假设之间的可比较性，从而降低了搜索错误。在假设扩展过程中，为了进一步减少搜索空间，翻译系统通过假设重组，丢弃无效假设。

本文中提出的交互式机器翻译相关内容均建立在短语翻译系统的基础上，特别是短语翻译系统的短语表、解码方法、模型参数训练等内容上。对短语机器翻译系统中的关键部分的理解有助于对本文的理解。

\chapter{地理选择题选项拆分}
\label{chapter:split}
\section{引言}
中文长句通常是一个复句，《现代汉语》对复句的定义为：复句是由两个或几个意义上紧密相关、结构上互不包含的分句构成的句子\cite{zhou2008}。这样的几个分句之间往往是由逗号分隔开的，因此根据上述定义，我们可以利用逗号在复句中的作用，将句子拆解成一些更简短的句子，从而降低句法分析、机器翻译、语义理解等等任务的难度。但是逗号除了可以分隔从句或是分句，在中文中也可以用来分隔并列的词语等等。

在地理试题中，尤其是选择题中，我们观察到一个现象：选择题的一个选项中（不考虑题面）经常包含一个或一个以上的逗号，而这个逗号常常隔开了两件或以上可以分别判断正误的部分，但也有一些逗号隔开的是具有因果、递进等关系的子句篇章。如果我们可以判断出哪些逗号隔开的是相对独立的两件事情，哪些逗号不能用来作为分割点将长句中两个句法上并列的部分隔开，则可以将较长的一个陈述句拆解成多个更短的、更简单的句子，能够大大减小例如句法分析及语义理解的分析难度。

所以为了更好地处理选择题中选项包含了逗号的长句，我们提出了一种对选项进行分类的方法，即根据逗号分开的两个句子部分的特点，判断该逗号隔开的是否是句法上可以视作并列的两个部分，进而将一些长句转换为几个短句。我们使用了最大熵模型进行分类，本章将介绍整个实验的方法及结果。

\section{相关工作}
在前期调研中，我们发现还没有一个已发表的研究十分类似于本节所提到的工作，一方面是因为逗号的处理在英文中的重要性要低于中文，因此对于逗号在句子分析和理解中的重视程度并不是很高，另一方面是因为本文所提出的方法是针对高考地理试题中的选择题这种特殊文本类型所提出的，并不十分适用于通用的中文文本。所以我们需要为我们研究的问题寻找一些理论基础，所以在本节中，我们根据Yang Y.Q.等人\cite{Yang2012Chinese}的研究工作，介绍他们在研究中文篇章关系时整理出的逗号在句子中的功能，这个分类与我们对逗号功能的判断和应用比较吻合。

上述工作将逗号的使用方法划分为7类，首先把逗号的使用方法在总体上分为两大类：一类是逗号连接的两个子句之间存在关系，即逗号是子句边界；另一类是两子句之间不存在关系，不能视作是子句或者是篇章的边界。两个子句之间存在的关系又可以分为并列关系和从属关系：并列关系可以分为三种类型（SB、IP_COORD、VP_COORD），从属关系也分为三种类型（ADJ、COMP、SBJ），图\ref{figure:comma_types}展示了这个分类体系。

\begin {figure}
	\centering
	\includegraphics[width=0.5\linewidth]{{comma}.jpeg}
	\caption{Yang的逗号分类体系}
	\label{comma_types}
\end{figure}

下面我们详细介绍一下每种类型的逗号的具体作用。

1）SB（Sentence Boundary）：在某些语境下，可以起到分割句子边界作用的逗号。这类逗号要求逗号左右的子句都是IP结构，父节点为根节点，比如在流水句中，如图\ref{figure:sb_comma}所示，该例中的两个逗号都是SB类型。

\begin {figure}
	\centering
	\includegraphics[width=0.5\linewidth]{{sb_comma}.jpeg}
	\caption{SB类型的逗号}
	\label{sb_comma}
\end{figure}

2）IP_COORD（IP Coordination）：分割父节点为非根节点的并列IP结构的逗号。如图\ref{figure:ip_coord}所示，其中的P4和P5属于这个类型。

\begin {figure}
	\centering
	\includegraphics[width=0.5\linewidth]{{ip_coord}.jpeg}
	\caption{IP_COORD类型的逗号}
	\label{ip_coord}
\end{figure}

3）VP_COORD（VP Coordination）：分割并列动宾短语的逗号，这些动宾短语共享同一个主语。如图\ref{figure:vp_coord}所示，其中的P6属于这个类型。

\begin {figure}
	\centering
	\includegraphics[width=0.5\linewidth]{{vp_coord}.jpeg}
	\caption{VP_COORD类型的逗号}
	\label{vp_coord}
\end{figure}

4)ADJ（Adjunction）：分割附属从句与主句的逗号。附属从句指在句子中担当某种句子成分的主属结构，虽然从句部分的句子结构是完整的，但它不能脱离主句部分独立完成地表达语义。附属从句往往是状语从句，通常有条件状语、原因状语、目的状语、方式状语、伴随状语等等。例如“为了在运行机制上与保护区相配套，宁波保护区率先在中国实施了企业依法注册直接登记制的试行一站式管理。”中的逗号前是一个目的状语。

5）COMP（Complementation）分割句子谓语与宾语的逗号。通常对于宾语部分较长的复杂句子，会在谓语之后出现逗号，表示停顿，用于舒缓语气，通常在“表示”、“指出”、“认为”、“介绍”等提示性动词之后都会出现逗号。例如“钱其琛表示，我们对香港的前景始终是充满信心的。”中的逗号。

6）SBJ（Subjective）：分割句子主语和谓语的逗号。在句法结构上表示为逗号的左兄弟节点为IP-SBJ或者NP-SBJ结构，而右兄弟节点为VP结构。例如“出口快速增长，成为推动经济增长的重要力量。”中的逗号。

除了以上六种逗号的用法，逗号还有一些其他的用法，但相对不太常见也不太有规律性，统称为其它类型逗号。

\section{选项拆分方法}
	

\section{实验及结果分析}
\section{本章小结}

\chapter{AMR语义理解}
\label{chapter:amr}
\section{引言}
在AMR出现以前，自然语言理解在语义分析上的工作还比较零散，例如实体连接、命名实体识别、语义角色标注等等工作，从某种意义上来说都属于语义理解的研究范畴。这样一来，实际上每一项研究都只关注了语义理解的一个方面，没有一个公认的完整的语义表达体系，能够将句子中的语义完整地描述出来。AMR的出现从某种程度上来说有希望能够解决这个问题，它是一种图表示方式，致力于将句子中的语义从表层的语法表示中抽象出来，将动作、实体、修饰等等各种语法要素都抽象成概念，然后以边来表示出概念之间的关系。

AMR作为一种新型的语义表示方法，目前看来是一种比较强大的、有潜力的语义表示，可以给自然语言理解带来一种新的研究方向，并对一些相关领域的研究或者工程性的工作带来结果上的提升\cite{kai2015improving}\cite{Pan2015}。因此，本文针对高考地理问答系统中的地理试题的理解，考虑了AMR这种新的方法，但由于AMR在中文的处理上暂时还是空白，可使用的工具和语料还很悠闲，目前还未进入实际应用阶段。我们有幸和中文AMR语料标注工作小组合作，得到了一些可用的中文语料，因此本文针对AMR的主要工作是对比现有算法在不同语言（中英文）、不同语料规模、不同语料类型、人工对齐与否等方面的性能，并在少量的地理试题AMR标注数据上进行了一些实验，为将来的应用工作打下基础。

\section{抽象语义表示（AMR）相关工作}

AMR是一种以有向的、简单的、类似树结构的（树出现环变成图的比例比较小）、边和节点有标记的图\cite{Banarescu2013Abstract}，可以将句子中的语义概念和概念之间的语义关系以节点和边的形式表现出来。

\begin {figure}
	\centering
	\includegraphics[width=0.5\linewidth]{{graph_amr}.png}
	\caption{AMR图表示}
	\label{graph_format}
\end{figure}

AMR有多种表现形式，根据定义可以以一个图的方式呈现出来，如\ref{figure:graph_format}；在图表示方法中，没有入边的节点就是根节点，在上图中就是“want-01”对应的节点。这张图是对“The boy wants the girl to believe him”这句话的AMR表示。这里总共有四个节点，每个节点都对应一个instance，实际上就是节点对应的概念。根节点是“want-01”对应的节点，后缀“-01”实际上是指定了这句中want这个谓词在Propbank体系中对应的语义框架，在这个语义框架下谓词有相应的多个论元，在这里就有arg0和arg1这两个论元。

这句话中有一个“want”动作，它的arg0（谁在want）是“boy”，它的arg1（want的是什么）是一个“believe”的动作；“believe”动作的arg0（谁在believe）是“girl”，它的arg1（believe什么）是“boy”。在这里“boy”有两个作用，一是作为“want-01”的arg0，一是作为“belive-01”的arg1，这个节点有两条入边，因此AMR图上出现了一个环，这在AMR中也叫做“重入”（reentrancy）。也正是因为“重入”现象的存在，使得AMR是一种图表示方法，而不是树表示方法。

上图这样的表示方法看起来稍有点复杂，AMR还可以以一种文本方式表达出来：\\
  (w / want-01 \\
     :ARG0 (b / boy)\\
     :ARG1 (b2 / believe-01\\
               :ARG0 (g / girl)\\
               :ARG1 b))\\

这里的第一行就是AMR的根节点，冒号后面的标签表示节点之间边的标记，也就是节点之间的关系。每个节点由变量名（斜杠前的部分）和概念（斜杠后的部分）组成（除了多次出现的同一个节点），如果一个节点出现多次，则通过让该节点的变量名多次出现来表示，如该例中的节点b。这里概念里的斜杠也可以看做是图表示方法中instance的简化表示。

AMR也可以用逻辑三元组的来表示，上面的例子可以表示成：
instance(w, want-01) \^      /* w 是want的实例 */ 
instance(b, boy) \^          /* b 是boy的实例 */ 
instance(b2, believe-01) \^  /* b2 是believing的实例 */ 
instance(g, girl) \^         /* g 是girl的实例 */ 
ARG0(w, b) \^                /* b 是want的发起者 */ 
ARG1(w, b2) \^               /* b2 是被want的东西 */ 
ARG0(b2, g) \^               /* g 是believe的人 */ 
ARG1(b2, b)                 /* b 是被believe的人 */

上面例子中的这句话在英文中还可以有很多种不同的表示方法，例如：
\begin{enumerate}
  \item The boy wants to be believed by the girl.
  \item The boy has a desire to be believed by the girl.
  \item The boy’s desire is for the girl to believe him.
  \item The boy is desirous of the girl believing him.
\end{enumerate}

概念want-01可以在句子中用动词want、名词desire或者形容词desirous来表达。

再比如下面这个AMR表示：\\
(p / permit-01 \\
     :ARG1 (g / go-02\\
              :ARG0 (b / boy))\\
     :polarity ))\\

也有很多种英文表达方式：
\begin{enumerate}
  \item The boy may not go.
  \item The boy is not permitted to go.
  \item It is not permissible for the boy to go.
  \item The boy does not have permission to go.
\end{enumerate}

由此可以看出，AMR更加强调句子表达的逻辑语义，并将表层的语法表达方式抽象出去。

AMR虽然是一种有向图表示，但是对于图的边和节点的关系仍然有一些限制条件\cite{Flanigan2014}：
\begin{enumerate}
  \item 简单性：应该是一个简单图，即任意两个概念节点之间最多有一条边
  \item 连通性：应该是弱连通图
  \item 确定性：对于某个节点，不能有标签相同的两条出边
  \item 无环性：图中没有环（有向边形成的首尾相连的环）
\end{enumerate}


\subsection{标注体系}
通过上文的介绍可知，AMR主要有两个部分组成：概念（节点）、概念间的关系（边）。下面将从这两个方面介绍AMR的标注体系。

\subsubsection{概念（concept）}
AMR的concept主要有三种来源：句中词语（例如\ref{figure:graph_format}中的“boy”）、propbank中的语义框架（例如\label{figure:graph_format}中的“want-01”）、抽象的关键字。

从之前举的例子可以看出，AMR试图对不同的表达方式甚至是相同语义的不同词语做出统一的标注方式。因此英文AMR对常见的concept制定了一个实体类型的标准列表，首先需要从这些实体名称中找出和想要描述的实体最相近的一个（例如有人会说“person”，有人会说“woman”，则可以通过这个列表统一起来）:
\begin{enumerate}
  \item person, family, animal, language, nationality, ethnic-group, regional-group, religious-group
  \item organization, company, government-organization, military, criminal-organization, political-party, school, university, research institute, team, league
  \item location, city, city-district, county, local-region, state, province, country, country-region, world-region, continent, ocean, sea, lake, river, gulf, bay, strait, canal, peninsula, mountain, volcano, valley, canyon, island, desert, forest, moon, planet, star, constellation
  \item facility, airport, station, port, tunnel, bridge, road, railway-line, canal, building, theater, museum, palace, hotel, worship-place, market, sports-facility, park, zoo, amusement-park
  \item event, incident, natural-disaster, earthquake, war, conference, game, festival
  \item product, vehicle, ship, aircraft, aircraft-type, spaceship, car-make, work-of-art, picture, music, show, broadcast-program
  \item publication, book, newspaper, magazine, journal
  \item natural-object
  \item law, treaty, award, food-dish, disease
\end{enumerate}

有时候句子中也会有单词指示该实体的类型，如果这个词比上述方式选择的类型更具体，则使用这个词代替，例如对于“the poet William Shakespeare”，可以用：
(p / poet\\
	:name (n / name :op1 "William" :op2 "Shakespeare"))\\

如果上述列表中所有实体名都没有合适的，句子中也没有明确指明实体的类型名称，就可以用“thing”来表示这个实体。例如对于“Words are the source of misunderstandings”，AMR中对“understanding”这个添加了“thing”这个concept：\\
(s / source-01\\
      :ARG1 (t / thing\\
            :ARG0-of (m / misunderstand-01))\\
      :ARG2 (w / word))\\

如果一个实体有多个类型，例如著名诗人、画家XXX，虽然同一种关系可以多次出现，但是:instance是AMR中唯一一种只能出现一次的关系，这时候可以使用:mod关系来修饰，例如对于“the poet Dr. Seuss”：\\
(d / doctor \\
	 :name (n / name \\
	 	    :op1 "Seuss")\\
	 :mod (p / poet))

还有一类概念用来表示数量：monetary-quantity , distance-quantity , area-quantity , volume-quantity , temporal-quantity , frequency-quantity , speed-quantity , acceleration-quantity , mass-quantity , force-quantity , pressure-quantity , energy-quantity , power-quantity , voltage-quantity (zap!-, charge-quantity , potential-quantity , resistance-quantity , inductance-quantity , magnetic-field-quantity , magnetic-flux-quantity , radiation-quantity , concentration-quantity , temperature-quantity ,score-quantity ,fuel-consumption-quantity , seismic-quantity。通常这类概念后面都会有一个quant关系指向表示具体数值的节点。

此外还有一些常见的concept列举如下：
\begin{enumerate}
	\item relative-position（相对位置）
	\item product-of和sum-of（数学运算）
	\item date-entity（时间）
	\item date-interval（时间区间）
	\item percentage-entity（百分比）
	\item phone-number-entity（电话号码）
	\item email-address-entity（电子邮箱）
	\item url-entity（url）
\end{enumerate}

对于特殊疑问句，AMR还对被提问的部分设计了一个amr-unknown概念。例如“What did the girl find?”:\\
  (f / find-01\\
    :arg0 (g / girl)\\
    :arg1 (a / amr-unknown))

\subsubsection{关系（relation）}
AMR在英文标注中大约有100种关系，比较常见的可以大致分成以下5个类型：
\begin{enumerate}
	\item 框架论元 :arg0,:arg1,:arg2,:arg3,:arg4,:arg5.
	\item 通用语义关系 :accompanier, :age, :bene ciary, :cause, :compared-to, :concession, :condition, :consist-of, :degree, :destination, :direction, :domain, :duration,:employed-by, :example, :extent, :frequency, :instrument, :li, :location, :manner, :medium, :mod, :mode, :name, :part, :path, :polarity, :poss, :purpose, :source, :subevent, :subset, :time, :topic, :value.
	\item 数量相关的关系 :quant, :unit, :scale
	\item 时间实体相关的关系 :day, :month, :year, :weekday, :time, :timezone, :quarter, :dayperiod, :season, :year2, :decade, :century, :calendar, :era.
	\item 列举关系 :op1, :op2, :op3, :op4, :op5, :op6, :op7, :op8, :op9,
:op10.
\end{enumerate}

对于所有的关系，AMR还允许这些关系的反转形式也作为关系标签，例如:arg0的反转形式为:arg0-of，:location的反转形式为:location-of。
除了上面列举的，还有一些其他的关系标签，不再一一列举。

\subsection{语料对齐与自动对齐}
AMR的语料对齐，即是将原句中的词语、词组与AMR图中的一个概念节点或者一个概念节点子图（例如一个时间概念子图，包括一个date-entity概念及其指向的表示年、月、日等信息的节点）进行对齐，这样的对齐信息对于自动解析算法有着重要的作用，例如在概念识别等阶段。图\ref{label:amr_align}给出了一个AMR节点与句子词语之间的对齐示意图。

\begin {figure}
	\centering
	\includegraphics[width=0.5\linewidth]{{align}.jpeg}
	\caption{AMR对齐}
	\label{amr_align}
\end{figure}

在语料建设工作中，不同的语料可能存在一个差异，即是否有对齐信息。目前英文的语料都是不含有对齐信息的，上文的例子都是这一类标注；中文已公布的1500句小王子语料也是不含有对齐信息的，但是即将公开的数据将对齐信息考虑了进去，嵌入了AMR的标注中，因本文的AMR部分工作是与含有对齐信息的语料标注团队合作，所以在我们的实验中也使用到了这一部分数据。

下面给出同一个中文句子的有对齐标注和无对齐标注两个版本，并进一步说明对齐信息是如何标注的。这个例子是对来自《小王子》语料中的一句话的两种标注，这句话分词的结果是“画 的 是 一 条 蟒蛇 正在 吞食 一 只 大 野兽 。”：

无对齐信息：\\
(x12 / 吞食-01 \\
      :arg0  (x14 / 蟒蛇\\
            :quant  (x15 / 1)\\
            :cunit  (x5 / 条))\\
      :arg1  (x16 / 野兽\\
            :mod  (x17 / 大-01)\\
            :quant  (x18 / 1)\\
            :cunit  (x10 / 只))\\
      :domain  (x19 / thing\\
            :arg1-of  (x20 / 画-01))\\
      :time  (x21 / 正在))\\

有对齐信息：\\
(x8 / 吞食-01\\
      :arg0  (x6 / 蟒蛇\\
            :quant  (x4 / 1)\\
            :cunit  (x5 / 条))\\
      :arg1  (x12 / 野兽\\
            :mod  (x11 / 大)\\
            :quant  (x9 / 1)\\
            :cunit  (x10 / 只))\\
      :domain  (x24 / thing\\
            :arg1-of  (x1 / 画-01))\\
      :aspect  (x7 / 正在))\\

可以看到，在AMR的整体结构上两者基本一致，最主要的差异在于变量（variable）名的选取。

对于无对齐信息的标注版本，在英文语料中，变量名通常是概念的首字母，如果出现了重复的首字母，则在后面添加一个数字来区分，例如“b2”等等。在中文语料中则通常是一个字母“x”加上一个数字，这个数字没有特别含义，只要能够将不同的概念区分开来即可。上述只是约定俗成的一种标注方式，并非标注规范要求，也可以采取别的方式来标注。

对于有对齐信息的标注版本，每个变量名中的数字都是有含义的。如果概念对应原文的某个词或者短语，呢么变量名的数字后缀就是对应的词或短语的下标（第一个词语的下标为1而不是0）；如果概念是新增的抽象概念，例如对于时间实体加了“date-entity”概念节点或者上面增加的“thing”这个概念，他们的数字下标是任意一个超过句子长度的数字，表示该概念不直接对应于句子中的词语，以免混淆。

在中文的对齐标注中，根据概念与句子分词结果中的对齐方式分类，有这几种情况：
\begin{enumerate}
	\item 对应一个词语：例如上面的“(x11 / 大)”，表示“大”这个概念对齐到句子的第11个词
	\item 对应多个词语：例如“ 那么 刺 有 什么 用 呢 ？ ”的AMR标注中有一个概念“x4\_x6 / 有用-01”，表示“有用-01”这个概念对齐到句子的第4和第6个词上。对于连续的词，也需要逐个写出对应的区间内的每一个词的下标，以免和上面这种跳词现象混淆。需要注意的是，在英文的AMR标注中，几乎没有跳词现象。
	\item 对应某个词语中的某几个字：例如“我 把 锤子 、 螺钉 、 饥渴 、 死亡 ， 全都 抛在 脑后 。”的AMR标注中有一个概念“x12\_1 / 抛-01”，表示“抛-01”这个概念对齐到句子的第12个词的第一个字上（如果是多个字则依次写出每个字在词中的下标，例如“x5\_1\_2\_3”）。
\end{enumerate}

关于自动对齐，Flanigan等人\cite{Flanigan2014}在提出JAMR解析算法的同时，为了训练概念节点的识别，提出了一种自动对齐的算法，主要是根据一系列的规则，用贪心算法来进行对齐，达到了92\%的准确率、89\%的召回率和90\%的F值，但是这种对齐方式只支持对概念节点和词语之间进行对齐，而没有考虑到有时边的label也是来源于某个词语，也存在对齐关系。Nima Pourdamghani等人\cite{Pourdamghani2014}提出了另一种自动对齐方式，该方法主要分为预处理、训练、后处理三步，在预处理阶段将AMR转换成一个字符串（保留关系的标签），然后进行小写化、去除停用词、去除词缀、去除等预处理，然后利用IBM的对齐模型进行训练，在后处理再重建出对齐好的AMR图。在对齐过程中，这种方式包含了边的标签信息，所以可以对边也进行对齐。


\subsection{自动解析算法}
Flanigan等人\cite{Flanigan2014}在2014年提出了一种两阶段的图算法JAMR，这是第一个公开的AMR自动解析算法，为后面的研究提供了一个较强的baseline。在2015年Wang Chuan\cite{Wang2015}等人观察到AMR表示与句法分析结果之间的相似性，提出了一种基于转换的AMR解析算法。Pust等人\cite{Pust2015}也在同年提出了一种使用基于语法的机器翻译的方法进行AMR的解析。Lucy Vanderwende等人\cite{Vanderwende2015}还提出了一种基于逻辑形式（Logical Form）到AMR的转换规则的解析方法，来处理没有大规模AMR标注语料的语言的AMR解析问题。本节重点介绍本文实验基于的JAMR图算法以及基于转换的AMR解析算法。

\subsubsection{基于图的算法}
Flanigan等人\cite{Flanigan2014}将AMR解析分成两个阶段：第一个阶段是从句子中识别出概念节点；第二个阶段是预测这些节点之间的边，也就是概念之间的关系。

在概念识别阶段，句子将会被切分成多个连续的片段（span），通过序列标注算法来实现，并将每一个片段对应于一个概念子图（AMR的一个片段，可能包含多个概念节点，例如一个时间实体包括一个date-entity概念和具体的年月日概念等等），这些概念子图都来自于训练语料中这些片段曾经对齐到的概念子图，或者是一个空图（即放弃这个片段到AMR的对应）。通过对一系列连续的句子子串\textbf{$b$}和一系列的概念图片段\textbf{$c$}进行打分（两者的个数均为k），使用公式\ref{equation:concept_iden}这个线性参数化函数进行优化，其中\textbf{$f$}是句子子串（span）和它可以对应的一个概念子图片段在上下文中的特征向量表示，包括词、长度、命名实体等等这些特征。

\begin{equation}
	\label{concept_iden}
	score(\textbf{b}, \textbf{c}; \textbf{$\theta$})=\sum_{i=1}^{k}\textbf{$\theta$}^\mathrm{T}f(\textbf{w}_{b_i-1\:b_i}, b_{i-1}, b_i, c_i)
\end{equation}

在关系识别阶段，则是基于第一个阶段识别出来的概念子图片段，在子图之间添加关系得到最终的AMR结果，这个结果需要满足五个条件，其中四个是在本章开头介绍过的AMR的有向图需要满足的四个条件：连通性、简单性、确定性、无环性，另一个就是保持性，即在第一阶段识别出所有概念子图片段应该是最终的AMR结果的子图。首先会对训练语料中的边训练一个线性参数的函数，特征为这条边的一些上下文，在解码的时候根据训练出的参数和函数对候选边进行打分。这个阶段的算法描述如下：边的候选集合为所有概念节点之间两两连接的有向边（两个方向，所有可能的边类型）；首先对于第一阶段识别出来的概念子图中已经存在的边，相应的节点对之间的其它边都不再作为候选边，这些存在的边成为AMR最终结果的组成部分；根据训练出的边打分函数，对未确定关系的节点对之间的所有候选边打分，保留分数最高的一条边，其他的不再作为候选；将所有得分大于0的边选出作为AMR最终结果的组成部分；对剩余的候选边，根据得分从高到底依次判断每条边是否进入最终结果，如果这条边可以将之前未相连的两个子图连接起来，则保留这条边；直至所有的节点之间形成一个弱连通图。根据实验结果，虽然算法未保证无环性，但是在所有测试数据上均未得到有环的结果。此外，上述算法过程可以保证连通性、简单性，但不能保证确定性，因此作者通过应用拉格朗日松弛法来保证确定性。

\subsubsection{基于转换的算法}
Chuan Wang等人\cite{Wang2015}提出了一种基于转换的AMR解析算法。这个算法也是两阶段算法：第一步先使用依存句法分析器得到句子的依存句法结果；第二步则是根据他们提出的基于转换的算法，将依存句法结果一步步转换到AMR图的结果。从语言学的角度来看，在一个句子的AMR和依存结构之间存在很多相似点：两者都有有向的节点间关系；AMR的概念和关系虽然是从居中实际使用的词语中抽象出来的，但是通常存在一些规律性的映射关系；句中的实词通常会保留在AMR结果中，虚词则常被忽略。从这些现象中可以感觉出，可以使用有限次转换动作，将一个依存句法树转换为AMR结果。

为了完成从句法分析到AMR的转换，作者设计了一系列转换的动作，并学习一个模型去决定在每次转换中采取哪个动作。包括如下这些动作：
\begin{enumerate}
	\item NEXT-EDGE-$l_r$：赋予一条边一个标签
	\item SWAP-$l_r$：将两个节点之间的边的方向反转，并给这条边赋予一个标签。这条边的新的head取代原head节点的位置，成为别的节点指向的节点。这个动作用于解决AMR和依存句法树对head的选择的差异。
	\item REATTACK\_k-$l_r$：为一个节点A重新选择一个head节点，即去除该节点原有的一条入边，将其与另一个节点建立一条新的边，这条新边仍是A的入边，同时给这个新边赋予一个标签。这个动作的出发点是，当反转了边之后，有些关联到旧的head节点上的节点应该重新关联到新的head节点上。
	\item REPLACE-HEAD：将某个节点A删除，然后让A指向的节点B取代被A的位置，也就是使A的head节点成为B的head节点。这个动作用于删除一些AMR中不包含但是依存句法树中包含的节点，例如介词等虚词节点。
	\item REENTRANCE\_k-$l_r$：	添加重入边，给某个节点和任意一个可能的其他节点之间添加一条新的边，在AMR结果中形成一个环。
	\item MERGE：将两个节点合并为同一个节点，让新节点继承旧的节点的所有出边和入边。这个动作通常用于为句子中连续的一个词语序列生成一个节点，通常可能对应一个命名实体，比如将一个名字的两个单词合并起来。
	\item NEXT-NODE-$l_c$：给某个节点赋予一个概念标签，然后将该节点从待处理节点队列中移除，开始考虑在下一个节点上采取什么动作。
	\item DELETE-NODE：删除一个节点及与其相关的所有边，这个动作只用于删除没有出边的节点，作用是删除一些功能词节点。
\end{enumerate}

该转换算法的状态是一个三元组($\sigma$,$\beta$,G)，$\sigma$存储所有待处理的节点，初始化成依存句法树中的所有节点，$\beta$存储$\sigma$中第一个节点的所有出边指向的节点，G存储当前的解析结果，初始化为依存句法树，算法结束后为得到的AMR结果。算法会训练一个在某个状态下对所有动作进行打分的函数，在每次转换前，找出所有动作中得分最高的那个，应用到当前的解析结果G上进行一次转换。打分函数的训练特征包括节点特征、节点对特征、路径特征、动作相关特征四类，涉及到词语、命名实体标签、依存句法等等句法和词法特征。

\subsection{自动评价}
目前，AMR最常用的评价方式是计算自动生成的AMR和测试集中的参考AMR的smatch得分\cite{Flanigan2014}\cite{Cai2013Smatch}。

\begin {figure}
	\centering
	\includegraphics[width=\linewidth]{{two_amr}.jpeg}
	\caption{两个待比较的AMR结果}
	\label{two_amr}
\end{figure}

在本章开头曾经介绍过，AMR可以以逻辑三元组集合的形式表示出来，例如对于图\label{two_amr}中左边的AMR，可以表示成：\\
instance(a, want-01) \^ \\
instance(b, boy) \^ \\
instance(c, go-01) \^ \\
ARG0(a, b) \^ \\
ARG1(a, c) \^ \\
ARG0(c, b)

三元组有两种形式，一种是relation(variable, concept)，另一种是relation(variable1, variable2)，例如上述前三行就是第一种三元组，后三行为第二种三元组。

对于图\label{two_amr}中右边的AMR，可以表示成：\\
instance(x, want-01) \^ \\
instance(y, boy) \^ \\
instance(z, football) \^ \\
ARG0(x, y)\^ \\
ARG1(x, z)

smatch就是计算两个AMR表示的三元组之间匹配的准确率、召回率和F值（通过将两个AMR中的变量名映射起来，然后计算两组三元组之间的相同的个数，再根据总的三元组个数计算准确率和召回率）。困难在于两个AMR所使用的变量名并不相同，所以两个AMR之间基于不同的变量映射方式，可以计算得到多种重合结果。smatch则定义为：将两个AMR之间的节点一一对应起来，所能得到的最大的F值。例如针对上面的例子，有六种变量匹配的方式，如表\ref{table:smatch_table}：

\begin{table}
\begin{center}
\begin{tabular}{c|c|c|c|c}
\hline {映射方式} & {M} & {P} & {R} & {F} \\
\hline x=a, y=b, z=c & 4 & 4/5 & 4/6 & 0.73 \\
\hline x=a, y=c, z=b & 1 & 1/5 & 1/6 & 0.18 \\
\hline x=b, y=a, z=c & 0 & 0/5 & 0/6 & 0.00 \\
\hline x=b, y=c, z=a & 0 & 0/5 & 0/6 & 0.00 \\
\hline x=c, y=a, z=b & 0 & 0/5 & 0/6 & 0.00 \\
\hline x=c, y=b, z=a & 2 & 2/5 & 2/6 & 0.36 \\
\hline
\hline smatch score & \multicolumn{4}{r}{0.73}\\
\hline
\end{tabular}
\end{center}
\caption{\label{table:smatch_table} 不同变量映射方式}
\end{table}

所以上面这个例子的smatch得分就是所有映射方式中所能得到的最大的F值0.73。虽然smatch的概念很简单明了，但是计算起来实际上没有这么简单，对于包含大量节点的AMR，枚举所有的可能的映射方式的时间复杂度很高，所以有一些高效的算法被用于计算近似的smatch值，例如爬山法等等，这超过了本文的介绍范围，所以不再展开。

\section{AMR在中文上的应用}
\section{实验及结果分析}
\section{本章小结}

\chapter{地理试题标注工具}
\label{chapter:tagger}
\section{引言}
\section{系统架构}
\section{功能说明及使用方法}
\section{本章小结}

\chapter{模型自适应}
\section{引言}
在前三章中，我们分别描述了基于短语翻译系统的PR交互翻译框架，PR交互翻译框架下的自动建议模型，以及PR交互翻译框架的扩展方法，即限制翻译片段的交互方法。在我们的交互框架下，用户可以使用简单的鼠标点击等操作进行人机交互，翻译系统根据交互信息在当前句子中进行限制解码，从而获得更优的翻译结果。

在上述交互框架中，系统只根据当前会话中保存的交互信息来提高当前句子的翻译质量，并没有将交互信息用于翻译系统中的统计模型本身中。本章主要描述交互翻译系统根据交互信息进行模型自适应的方法。模型自适应方法可以交互信息与翻译系统中的统计模型相结合，从而提升翻译系统翻译能力。在上一章中，由于我们并没有进行大规模的限制片段模拟交互实验，而是进行了小规模的人工交互实验，所以产生的交互信息少，没有足够的数据进行模型自适应。在此背景下，本章主要描述使用PR 交互框架下产生的交互信息进行模型自适应的方法。
\section{典型方法及其不足}
\label{section:typical}
Germann等人\cite{germann2014dynamic}于2014年提出了使用动态短语表的模型自适应方法。该方法的主要思想是按需加载短语表\cite{zens2007efficient}和双语采样。在翻译一个源语言句子时，首先按照该句的内容在训练数据集中进行双语采样，进而在采样出的小规模样本上抽取短语表并加载到内存中。对于一个源端句子，当用户完成交互翻译后，最终生成的翻译都被认为是正确的，所以系统可将该句及其最终翻译对作为训练数据加入训练语料中。系统就可以在更新后的训练语料上利用动态短语表来影响后续句子的翻译，从而起到模型自适应的作用。

为了降低双语采样的时间开销，Germann等人使用了后缀数组来组织双语训练语料。在此基础上，Germann等人还将短语表表示为二进制形式，并使用内存映射等技巧来提高读入效率。经过上述优化后，与传统的短语表表示方法相比（预先将短语表全部读入内存，使用时基于哈希技术进行常数时间查询），时间开销可比较。

虽然Germann等人的方法可以做到实时更新训练语料，但由于该方法必须从语料中采样出少部分样本，所以会带来搜索空间的损失，进一步可能导致翻译质量的损失；其次，该方法也没有更新翻译系统的对数线性模型的参数，忽略了模型参数对翻译系统质量的影响。

Marie等人\cite{marietouch}于2015年提出基于触控的预-后处理（Touch-based Pre-post-editing, PPE）的方法。该方法首先让翻译系统生成原始翻译，进而让用户标记原始翻译结果中哪些片段应该出现在最终翻译中（正确的片段），哪些片段不应该出现在最终翻译中（错误的片段）。当用户对每个句子的翻译标记结束后，系统从这些标记好的片段中根据词对齐抽取正、负翻译模型（正确片段中抽出的短语对为正，反之为负），并将原先短语表中对应的翻译选项去除；同时，从这些标记好的片段中训练$n$ 元文法正、负语言模型，正负的定义与正负翻译模型一致；最后，PPE方法将四个模型作为额外特征加入到机器翻译系统中的对数线性模型中，并重新训练模型参数。

虽然PPE方法能够抽取出补充模型并更新模型参数，但是PPE方法实际上并没有将用户信息充分利用起来。用户标记的内容只被用于被用户标记过的句子中，对新句子不起作用，所以实际上并不能起到模型自适应的作用。

\section{自适应流程及方法}
\label{section:adapt}
图\ref{figure:adaptationFlow}给出了模型自适应的流程。用户使用本文提出的PR交互翻译框架进行交互翻译，系统可以在人机交互不断进行的过程中捕获所有交互信息，当捕获到的信息量足够多时进行模型自适应。


\tikzstyle{decision} = [diamond, draw, aspect=1.5,
    text width=5em, text badly centered, inner sep=0pt]
\tikzstyle{block} = [rectangle, draw,
    text width=8em, text centered, rounded corners, minimum height=1.6em]
\tikzstyle{dashblock} = [rectangle, draw,dashed,
    text width=8em, text centered, rounded corners, minimum height=1.6em]
\tikzstyle{circle} = [rectangle, draw, text width=4em, text centered, rounded corners, minimum height=1.6em]
\tikzstyle{line} = [draw, -latex'] \tikzstyle{cloud} = [draw, ellipse, node distance=3cm,
    minimum height=2em]
\begin {figure}[ht]
\centering
\begin{tikzpicture}[node distance = 1.8cm, auto]
    % Place nodes
    \small
    \node [circle] (start) {开始};
    \node [block, below of=start] (constrain) {限制解码器};
    \node [decision, right of=constrain, node distance=4.2cm] (adapt) {信息收集足够？};
    \node [decision, below of=constrain, node distance=2cm] (decide) {可接受?};
    \node [block, right of=start, node distance=4.2cm] (learn) {模型自适应};
    \node [block, right of=decide, node distance=4.2cm] (interact) {交互};
    \node [circle, below of=decide, node distance=2cm] (stop) {结束};
    % Draw edges
    \small
    \path [line] (start) -- node{$s_1 ... s_n$}(constrain);
    \path [line] (constrain) -- node{$e_1 ... e_n$}(decide);
    \path [line] (decide) -- node [near start] {否} (interact);
    \path [line] (interact) -- node{($s_{i}^{j}$,$t'$)}(adapt);
    \path [line] (adapt) -- node{($s_i^j$,$t'$)}(constrain);
    \path [line] (decide) -- node {是}(stop);
    %\draw [->,dashed] (adapt) -- node{($s_i^j$,$t'$)}(learn);
    %\draw [->,dashed] (learn) -- (constrain);
    \path [line] (adapt) -- node{是}(learn);
    \path [line] (learn) -- (constrain);
\end{tikzpicture}
\caption {\label{figure:adaptationFlow} 模型自适应流程图}
\end{figure}

本文提出的模型自适应方法对上文中描述的典型方法中存在的问题作出改进。一方面，我们仍然使用传统的短语表表示方法，即在翻译任务开始之前，预先将短语表读入内存中，使得翻译系统在使用短语表时可以以常数时间读取，且不丢失已有的翻译选项。我们将短语表表示为二进制文件，并使用内存映射等方法提升短语表、语言模型等的读入效率。另一方面，我们使用了三种不同的方法进行模型自适应，分别是补充翻译模型方法，翻译模型插值方法和翻译模型修正方法。我们的方法改进了Marie 等人的PPE方法，解决了其不具有泛化能力的问题。在上述三种方法的基础上，我们根据对真实实验结果的分析，进一步将翻译模型插值方法和翻译模型修正方法相结合，更大程度上提升了翻译系统的翻译性能。

\subsection{补充翻译模型}
\label{section:Supplementary}
补充翻译模型方法（Supplementary Translation Model, STM）的主要思想是在现有的模型的基础上补充新的翻译模型。我们首先给出PRP与翻译选项一致的定义：当一个给定PRP 与一个给定翻译选项的源端完全相同，目标端也完全相同，则称两者一致。

我们将交互过程中产生的每个PRP记录下来，并将基线系统的翻译模型中与该PRP 一致的翻译选项加入到补充翻译模型中，所以补充翻译模型实际上是基线系统中的翻译模型的子集。我们将补充翻译模型作为$4$ 维扩展特征，其对应的词汇化调序模型作为另外$6$ 维扩展特征，共$10$ 维扩展特征加入到短语翻译系统的对数线性模型中并调节模型参数。模型自适应的具体过程如下：
\begin{enumerate}
  \item 初始时，补充翻译模型为空，被加入到对数线性模型中。初始化补充翻译模型的权重的方法与标准的翻译模型的权重初始化方法一致。由于初始时补充翻译模型中不包含任何翻译选项，所以其各项特征值都为0。
  \item 用户使用PR交互框架进行交互翻译，对于数据集中的每个源语言句子，每次PR交互产生一个PRP， ($s_i^j, t$)。
  \item 系统接收($s_i^j, t$)，进行限制解码，生成新的句子翻译 $e$，并将($s_i^j, t$)存储起来。
  \item 当接收到一定量的数据时，将基线系统的翻译模型中所有与PRP一致的翻译选项组织成补充翻译模型$TM_s$，以二进制形式存储。
  \item 系统将补充翻译模型读入内存，将其作为对数线性模型的新特征，使用开发集进行最小化错误率训练，更新模型参数。
  \item 重复步骤2到4直至翻译任务结束。
\end{enumerate}

用户可以使用PR交互框架进行多轮交互，系统可以根据收集到的交互信息进行多轮模型自适应以持续提升翻译质量。

\subsection{翻译模型插值}
\label{section:interporlation}
在第\ref{section:Supplementary}节中，我们描述了使用补充翻译模型进行模型自适应的方法。这种方法在翻译系统中加入了一个补充翻译模型$TM_s$，并调节模型参数。该方法有一个潜在缺点是，当翻译系统使用与某个PRP一致的翻译选项进行假设扩展时，$TM$ 中的特征与$TM_s$中的特征同时被激活，这就削弱了系统对PRP与非PRP的区别能力。

本节中，我们针对上述问题，对补充翻译模型作出改进，提出翻译模型插值（Translation Model Interpolation, TMI）的方法。该方法与补充翻译模型方法类似，都是迭代更新的过程。不同的是，当收集到一定数量的PRP后，系统一方面将与PRP一致的翻译选项组织成补充翻译模型$TM_s$，$TM_s$中各项概率值的设置方法与上一节一致；另一方面，将基线系统中的翻译模型$TM$中所有与PRP一致的翻译选项去除，得到$TM'$。由于$TM_s$ 实际上是$TM$ 的一个子集，所以这样的设置方法保证了$TM'$ 与$TM_s$的交集为空。在这种设置下，我们将$TM'$ 与$TM_s$ 作为两个不同的翻译模型，加入到对数线性模型中。我们用$TM'$ 取代$TM$，以$TM'$ 作为翻译系统主要使用的翻译模型，$TM_s$作为补充翻译模型，并使用MERT 进行模型参数的调节。

由于$TM_s$与$TM'$交集为空，所以$TM_s$与$TM'$作为两个独立的部分在对数线性模型中起作用，两者互不影响。该方法实际上相当于两个翻译模型的对数线性插值，故本方法被称为翻译模型插值法。与补充翻译模型的方法相同，系统可以进行多轮模型自适应训练，从而逐步提高翻译质量。
\subsection{翻译模型修正}
\label{section:modify}
在第\ref{section:Supplementary}节和第\ref{section:interporlation}节中，我们分别描述了补充翻译模型和翻译模型插值两种模型自适应的方法。这两种方法均使用了补充翻译模型的概念，都在现有的对数线性模型上加入额外的10维特征进行参数训练。这两种方法存在一定的弱点，一方面都扩大了参数空间，使得参数训练过程相对更复杂；另一方面，都没有更新翻译模型本身的概率分布，而传统的模型自适应方法通常采用更新模型概率分布的方法并取得了一定成功。

本节中，我们针对上述问题，提出了翻译模型修正（Translation Model Modification, TMM）的方法。该方法仍然是迭代更新的过程。与前两节中的方法不同，一方面，该方法不需要扩大参数空间，其参数训练的过程与翻译系统本身的参数训练过程完全一致；另一方面，该方法根据交互信息对翻译模型本身的概率分布做修正从而达到模型自适应的目标。

直观而言，人机交互中产生的PRP在翻译中应该起更重要的作用，所以其翻译概率应该更高。我们基于这种思想利用收集到的PRP来更新翻译模型的概率分布。具体地，每当PRP出现一次（用户在交互过程中使用了该PRP），该PRP 的计数加一。当收集到一定量的PRP 后，根据PRP的出现次数提高与该PRP 一致的翻译选项的翻译概率，并利用新得到的翻译模型重新训练模型参数。

翻译概率的具体更新方法见算法\ref{algorithm:modifymodel}，其根本思想是根据PRP出现的次数来修正翻译选项的正向、逆向翻译概率，并进行归一化。当一个翻译选项与某个PRP，($s, t$)，一致时，以公式\ref{equation:update1}的幅度增加其正向、逆向翻译概率，并进行归一化。
\begin{equation}
\label{equation:update1}
  count(PRP|PRP.source==s, PRP.target==t) * \alpha
\end{equation}

其中，$count$表示该PRP，($s,t$)，出现的次数，$\alpha$ 是一个超参（Hyper Parameter），表示用户对PRP 的信任程度。另外，我们还需要对短语表中其他相关的翻译选项的正向、逆向翻译概率进行归一化。当翻译选项($s,t$) 的源端$s$ 与某个PRP 的源端$PRP.source$ 相同，但目标端不同时，需要使用公式\ref{equation:norm1}归一化其正向翻译概率。

\begin{equation}
  \label{equation:norm1}
  p(t|s)=\sfrac{p(t|s)}{(1 + \alpha*count(PRP|PRP.source == s))}
\end{equation}
其中$count(PRP|PRP.source == s)$表示源端为$s$ 的PRP 的数目，$\alpha$的定义与公式\ref{equation:update1}中一致。

类似的，当($s,t$) 的目标端$t$ 与某个PRP 的源端$PRP.target$ 相同，但源端不相同时，需要使用公式\ref{equation:norm2}归一化其逆向翻译概率。
\begin{equation}
  \label{equation:norm2}
    p(s|t) = \sfrac{p(s|t)}{(1 + \alpha*count(PRP|PRP.target == t))}
\end{equation}
其中$count(PRP|PRP.target == t)$ 表示目标端为$t$的PRP的数目，$\alpha$的定义与公式\ref{equation:update1}中一致。

当($s,t$) 不与任何PRP相关（源端、目标端都不相同），则其翻译概率不需要改变；这样的概率更新方法可以使得与PRP一致的翻译选项的翻译概率得到提升，其他相关的翻译选项的翻译概率下降，完全无关的翻译选项则不受影响。

\begin{algorithm}
\begin{algorithmic}[1]
\FOR{all (s,t) $\in$ TM}
    \IF{$\exists PRP\in PRPs$ and $PRP.source == s$ and $PRP.target == t$}
        \STATE $p(t|s) = \sfrac{(\alpha * count(PRP) + p(t|s))}{(1 + \alpha*count(PRP))}$
        \STATE $p(s|t) = \sfrac{(\alpha*count(PRP) + p(s|t))}{(1 + \alpha*count(PRP))}$
    \ELSIF{$\exists PRP\in PRPs$ and $PRP.source == s$ and $PRP.target~!= t$}
        \STATE $p(t|s) = \sfrac{p(t|s)}{(1 + \alpha*\sum_{PRP'.source == s}count(PRP'))}$
    \ELSIF{$\exists PRP\in PRPs$ and $PRP.source~!= s$ and $PRP.target == t$}
        \STATE $p(s|t) = \sfrac{p(s|t)}{(1 + \alpha*\sum_{PRP'.target == t}count(PRP'))}$
    \ELSE
        \STATE continue;
    \ENDIF
\ENDFOR
\end{algorithmic}
\caption{\label{algorithm:modifymodel}翻译模型概率修正计算方法}
\end{algorithm}

\subsection{模型插值与模型修正相结合}
\label{section:combination}
在前三节中，我们分别描述了补充翻译模型、模型插值和模型修正三种基础的模型自适应方法。这三种模型自适应方法各有特点，也可以在一定程度上提升翻译系统的性能。

%本节主要描述将模型插值与模型修正相结合的模型自适应方法。我们首先给出两个结论，这两个结论是我们将模型插值与模型修正相结合的动机和基础，并且将在第\ref{experiment:adaptation}节中的实验部分被验证：
%\begin{enumerate}
%  \item 相比补充翻译模型的方法和模型修正的方法，模型插值的方法能够更大程度地提高翻译系统的翻译能力。
%  \item 相比补充翻译模型和模型插值的方法，模型修正的方法更新了翻译选项的概率分布，能够带来翻译质量的提升。
%\end{enumerate}
%
%在以上结论的支持下，
我们将模型插值方法与模型修正方法相结合，综合两者的优势，期望能够最大程度地提升翻译系统的性能。具体地，我们在第\ref{section:interporlation} 节中的模型插值方法的基础上作出改进，一方面仍然将PRP组织成补充翻译模型$TM_s$，并将短语系统本身的翻译模型$TM$中对应的部分去除，得到$TM'$；另一方面，使用第\ref{section:modify} 节中的方法修正$TM_s$和$TM'$中翻译选项的概率分布，而非直接使用$TM$ 中的概率分布。在此基础上，用$TM'$ 替代$TM$，并将$TM_s$ 加入对数线性模型，使用MERT 调节模型参数。

\section{实验及结果分析}
\label{experiment:adaptation}
\subsection{实验配置及实验方法}
本章使用的短语翻译系统仍然与第\ref{experiment:primt}章中描述的一致，具体在此不再赘述。

因为真实的人工交互代价昂贵且耗费时间，所以我们在实验中使用了模拟PR 交互操作（见第\ref{sec:simulate} 节）。我们在NIST02与NIST03 数据集的并集NIST0203 上进行交互翻译实验，每轮交互都修正数据集中每句的最关键的错误。当对数据集中每个句子都进行一次PR 交互后，完成一轮整个数据集上的PR 交互，随后系统开始使用NIST0203 作为开发集$c$ 开始模型自适应，进而完成一轮模型自适应。

\subsection{模型自适应对翻译质量的影响}
\subsubsection{补充翻译模型对翻译质量的影响}
表\ref{table:adaptation1}给出了补充翻译模型的模型自适应方法对翻译质量的影响。第一行给出了数据相关信息，第二行表示基线系统在三个数据集上的翻译得分。STM*$n$表示进行了$n$轮补充翻译模型自适应方法后，翻译系统在三个数据集上的翻译得分。

\begin{table}[!htb]
\begin{center}
\begin{tabular}{c|c|c|c}
\hline
数据& NIST0203 & NIST04 & NIST05\\
\hline
基线系统 & 30.29 & 31.83 & 30.64 \\
\hline
STM*1 & 32.87 (+2.58) & 32.17 (+0.34) & 30.62 (-0.02)\\
\hline
STM*2 & 34.15 (+3.86) & 32.63 (+0.80) & 30.91 (+0.34)\\
\hline
STM*3 & 35.12 (+4.83) & 33.04 (+1.21) & 31.22 (+0.58)\\
\hline
\end{tabular}
\end{center}
\caption{\label{table:adaptation1} 补充翻译模型自适应方法对翻译质量的影响}
\end{table}

从表\ref{table:adaptation1}中可以看出，在第一轮模型自适应后，虽然系统平均在每个句子中只捕获了一个PRP，但是对于当前开发数据NIST0203而言，翻译质量提升了2.58 BLEU，这样的提升已经非常明显。这样的结果证明了补充翻译模型的模型自适应方法的有效性。对于NIST04 数据集，使用模型自适应后的系统进行解码，BLEU 得分从31.83 变为32.17 (+0.34)；对于NIST05 数据集，BLEU 得分从30.64 变为30.62 (-0.02)。NIST04 数据集的翻译质量上升，NIST05几乎不变。这样的结果表明当前的系统泛化能力还不够强，需要更多交互数据继续进行模型自适应。

第二轮模型自适应（STM*2）后，NIST0203的翻译质量进一步提升（+3.86 BLEU）。NIST04和NIST05两个数据集的BLEU得分分别提高了0.80和0.34。相比第一轮模型自适应，NIST04的翻译质量进一步提升，NIST05的翻译质量从几乎无变化到统计显著的提升。这样的结果说明在两轮自适应后，系统的泛化能力得到了一定程度的增强。第三轮模型自适应（STM*2）后，系统在三个数据集上的翻译质量继续提升，这说明补充翻译模型的模型自适应方法可以在不断迭代的过程中持续提升翻译系统的翻译能力。
\subsubsection{翻译模型插值对翻译质量的影响}
表\ref{table:adaptation2}给出了翻译模型插值的模型自适应方法对翻译质量的影响。第一行给出了数据相关信息，第二行表示基线系统在三个数据集上的翻译得分。TMI*$n$表示进行了$n$轮翻译模型插值自适应方法后，翻译系统在三个数据集上的翻译得分。

\begin{table}[!htb]
\begin{center}
\begin{tabular}{c|c|c|c}
\hline
数据& NIST0203 & NIST04 & NIST05\\
\hline
基线系统 & 30.29 & 31.83 & 30.64 \\
\hline
TMI*1 & 33.27 (+2.98) & 32.50 (+0.67) & 30.98 (+0.34)\\
\hline
TMI*2 & 35.01 (+4.72) & 32.95 (+1.12) & 31.47 (+0.83)\\
\hline
TMI*3 & 36.35 (+6.06) & 33.54 (+1.71) & 31.87 (+1.23)\\
\hline
\end{tabular}
\end{center}
\caption{\label{table:adaptation2} 模型插值自适应对翻译质量的影响}
\end{table}

从表\ref{table:adaptation2}中可以看出，在第一轮模型自适应后，与补充翻译模型的自适应方法相似，当前开发数据（NIST0203）的翻译质量有明显的提升（+2.98），且提升更为明显，这说明了模型插值的自适应方法对于开发集更有效。对于NIST04 数据集，使用模型自适应后的系统进行解码，BLEU 得分进一步提升（+0.67），相比补充翻译模型的方法，翻译质量的提升程度更大；对于NIST05 数据集，BLEU得分有+0.34 的提升，仍然比补充翻译模型的方法提升程度更大。

第二轮模型自适应（TMI*2）后，对于三个数据集，NIST0203，NIST04，NIST05分别有+4.72，+1.12，+0.83的BLEU 提升。继续进行第三轮模型插值自适应（TMI*3），NIST0203的翻译质量提升了+6.06 BLEU，NIST04和NIST05也分别有+1.71 和+1.23 的BLEU 提升，这样的提升已经非常显著，说明翻译模型插值的方法同样可以在不断迭代的过程中持续提升翻译系统的翻译能力。相比补充翻译模型的方法，翻译模型插值方法对翻译系统的翻译能力提升更明显，这样的结果说明了模型插值的方法相比基于补充翻译模型的方法更优。
\subsubsection{翻译模型修正对翻译质量的影响}
表\ref{table:adaptation3}给出了翻译模型修正的自适应方法对翻译质量的影响。第一行给出了数据相关信息，第二行表示基线系统在三个数据集上的翻译得分。TMM*$n$表示进行了$n$轮翻译模型修正自适应方法后，翻译系统在三个数据集上的翻译得分。接下来两行分别表示$\alpha$取值不同时，进行一轮模型自适应后三个数据集上的翻译得分。其中$\alpha$系统表示对PRP的信任程度，可根据实际情况调整。

\begin{table}[!htb]
\begin{center}
\begin{tabular}{c|c|c|c}
\hline
数据& NIST0203 & NIST04 & NIST05\\
\hline
基线系统 & 30.29 & 31.83 & 30.64 \\
\hline
TMM*1 ($\alpha = 0.1$) & 31.90 (+1.61) & 31.92 (+0.09)& 30.63 (-0.01)\\
\hline
TMM*2 ($\alpha = 0.1$) & 32.71 (+2.42) & 32.31 (+0.48)& 31.16 (+0.52)\\
\hline
TMM*3 ($\alpha = 0.1$) & 33.41 (+3.12) & 32.85 (+1.02)& 31.58 (+0.94)\\
\hline
\hline
TMM*1 ($\alpha = 0.3$) & 32.34 (+2.05)& 31.88 (+0.05) & 30.63 (-0.01)\\
\hline
TMM*1 ($\alpha = 0.5$) & 32.93 (+2.64)& 31.69 (-0.14) & 30.47 (-0.15)\\
\hline
\end{tabular}
\end{center}
\caption{\label{table:adaptation3} 模型修正自适应对翻译质量的影响}
\end{table}

从表\ref{table:adaptation1}中可以看出，在第一轮模型自适应后，当前开发数据（NIST0203）的翻译质量有较明显的提升（+1.61），相比补充翻译模型和模型插值方法，模型修正的方法带来的翻译质量的提升幅度相对较小。NIST04 和NIST05 数据集的翻译质量几乎无变化，说明当前模型自适应的泛化能力还较弱。

第二轮模型自适应（TMM*$2$）之后，NIST0203 的BLEU 得分从31.83 变为32.71 (+2.42)，NIST04 的BLEU 得分从31.83变为32.31 (+0.48)，NIST05 的BLEU 得分从30.64 提升到31.16 (+0.52)，虽然翻译质量的提升幅度没有前两种方法大，但是提升也已经比较明显，说明系统在交互信息变多的情况下，泛化性得到了增强。在第三轮模型自适应（TMM* $3$） 之后，三个数据集的结果相比之前的结果又有了一定提升，说明该方法的泛化性能进一步提升。这样的结果说明翻译模型修正的自适应方法也可以在不断迭代的过程中持续提升翻译系统的翻译能力。

我们同样对比了不同$\alpha$对翻译质量的影响。当$\alpha$分别为0.1, 0.3, 0.5时，对当前开发数据集NIST0203而言，BLEU得分分别为31.90 (+1.61)，32.34 (+2.05)，32.93 (+2.64)，这说明$\alpha$ 越大，开发集的翻译质量提升越明显。对于NIST04和NIST05两个数据集，当$\alpha=0.1$ 和$\alpha=0.3$ 时，进行一轮模型自适应后翻译质量几乎无变化；当$\alpha=0.5$ 时，两个数据集上的翻译质量都有一定程度的降低，这说明此时$\alpha$ 的取值过大，造成了模型的过拟合，导致泛化能力降低。在实际应用中，我们需要根据实际情况进行$\alpha$的取值。
\subsubsection{翻译模型插值与翻译模型修正相结合对翻译质量的影响}
表\ref{table:adaptation4}给出了翻译模型插值和翻译模型修正相结合的自适应方法对翻译质量的影响。第一行给出了数据相关信息，第二行表示基线系统在三个数据集上的翻译得分。(I+M)*$n$表示进行了$n$轮模型自适应方法后，翻译系统在三个数据集上的翻译得分。其中$\alpha$的取值为0.1。

\begin{table}[!htb]
\begin{center}
\begin{tabular}{c|c|c|c}
\hline
数据& NIST0203 & NIST04 & NIST05\\
\hline
基线系统 & 30.29 & 31.83 & 30.64 \\
\hline
(I+M)*1 ($\alpha = 0.1$) & 33.32 (+3.03) & 32.56 (+0.73)& 31.09 (+0.45)\\
\hline
(I+M)*2 ($\alpha = 0.1$) & 35.53 (+5.24) & 33.11 (+1.28) & 31.84 (+1.20)\\
\hline
(I+M)*3 ($\alpha = 0.1$) & 36.48 (+6.19) & 33.78 (+1.95) & 32.21 (+1.57)\\
\hline
\end{tabular}
\end{center}
\caption{\label{table:adaptation4} 模型插值与模型修正结合自适应对翻译质量的影响}
\end{table}

从表\ref{table:adaptation4}中可以看出，在第一轮模型自适应后，当前开发数据集（NIST0203）的翻译质量有明显的提升（+3.03），相比前三种方法，翻译质量的提升更大。对于NIST04 和NIST05 数据集，BLEU得分分别提高了0.73和0.45，相比前三种方法，翻译质量的提升仍然更高，这说明了该方法的泛化能力更强。

在第二轮模型自适应（(I+M)*$2$）之后，NIST0203 的BLEU 得分继续提升（+5.24），NIST04 与NIST05 的BLEU 得分分别提高了+1.28和+1.20。在第三轮模型自适应（(I+M)* $3$）之后，三个数据集的结果相比之前的结果又有了一定提升，分别提升了6.19，1.95和1.57 BLEU，且提升都比前三种方法更大，这说明将翻译模型插值与翻译模型修正相结合的方法可以同时发挥模型插值和模型修正两种方法各自的优势，更大程度地提升翻译系统的能力。

\subsection{模型自适应方法对比}
本章所提出的模型自适应方法之间互有联系也互有区别。

首先，本文提出的模型自适应方法都是迭代的过程，可以不断地使用人机交互信息提升翻译系统的性能；其次，都需要使用MERT 来调整模型参数。

在对翻译质量的提升方面，三种基本的模型自适应方法中翻译模型插值的方法能力最强；其次是补充翻译模型的方法；最后是翻译模型修正的方法。其中，模型修正的方法需要结合用户先验和实际系统确定$\alpha$的取值，取值的不同对翻译质量有一定影响。在交互信息不断增多的情况下，三种方法对翻译质量的提升能力都会逐步加强。将翻译模型插值与翻译模型修正的方法相结合的方法能够发挥两者的优势，更大程度地提高翻译系统的翻译性能。

在时间复杂度方面，因为三种基本方法都使用MERT来进行参数学习，所以三者的时间复杂度没有本质差别。补充翻译模型和翻译模型插值的方法都在短语翻译系统的对数线性模型的基础上增加了10 维特征，扩大了特征空间；翻译模型修正的方法直接修正短语表中的翻译概率，不影响特征空间，所以训练过程相对较快。将翻模型插值与翻译模型修正的方法相结合的方法的训练时间复杂度与翻译模型插值方法一致。

在空间复杂度方面，除翻译模型修正方法之外，其他模型自适应方法都需要额外的空间存储一个新的翻译模型。随着交互翻译的不断进行，产生的交互信息越来越多，新的翻译模型所需的空间也将越来越大。

\section{本章小结}
本章针对传统的机器翻译系统中典型的模型自适应方法中存在的若干问题，提出了基于选择-修正交互框架的翻译系统模型自适应的方法。

我们提出了三种基本方法，分别是补充翻译模型、翻译模型插值、翻译模型修正的方法。补充翻译模型的方法将基线系统的翻译模型中与PRP一致的翻译选项整合成新的翻译模型，并将其作为新特征加入到对数线性模型中，进而使用MERT调节模型参数；翻译模型插值的方法建立在补充翻译模型的基础上，将补充翻译模型与基线系统的翻译模型完全区分开，同样使用MERT 调节参数；翻译模型修正方法根据PRP 的出现频次对翻译选项的概率分布进行修正，进而采用MERT进行参数调节。在三种基本方法的基础上，将翻译模型插值方法和模型修正方法相结合可以发挥两者各自的优势。

实验结果表明，在进行一定量的人机交互之后，本章提出的模型自适应方法不仅能带来开发集翻译质量的显著提升，而且具有较强的泛化能力，可以切实提升翻译系统的能力。将模型插值与模型修正相结合的方法对翻译系统能力的提升最大。

模型自适应方法可以与本文提出的选择-修正交互翻译框架融为一体，作为交互翻译系统的一部分，利用交互过程中产生的信息来提升翻译系统的翻译能力。用户在使用交互翻译系统的过程中，一方面可以使用本文提出的PR交互框架进行交互，实时提高当前翻译的质量；另一方面，将交互信息提供给系统，系统利用模型自适应方法提升翻译性能，从而降低交互需求。
\chapter{总结与展望}
\section{工作总结}
主流的交互式机器翻译框架采用自左向右进行句子翻译补全的方法 （Left-to-Right, L2R），用户输入句子翻译，系统根据用户的输入不断提供补全建议，用户既可以接受建议也可以拒绝建议。虽然L2R的框架取得了较大成功，但该框架难以优先修正句末的关键错误。当一个关键错误出现在句末，而该翻译错误又导致了句首的翻译错误，从左到右进行翻译修正就会延迟对该错误的修正，从而可能导致交互效率的低下。

对于以上问题，本文从以下几方面展开了具体工作：
\begin{enumerate}
  \item 提出了选择-修正的交互式机器翻译框架（Pick-Revise, PR）。 选择-修正框架是一个迭代式的交互翻译框架，在这种框架下，用户的交互只需要两个简单的操作即可完成（选择和修正），用户可以修正任何句子中任意位置的翻译错误，以此来提高交互翻译效率，减少用户交互次数。基于该框架，我们提出交互翻译的限制解码算法，使机器翻译系统能够自然地利用用户提供的信息进行解码，并获得更优翻译结果。实验结果表明，对比L2R 和PE系统，我们的PR交互框架可以在极少的用户操作下（3.3\% KSMR），带来翻译质量的大幅提升（+17 BLEU）。
  \item 在PR翻译框架的基础上，对用户的两种操作分别提出了自动建议模型，包括选择建议模型和修正建议模型。选择自动建议模型可以预测出可能是翻译关键错误的短语并建议用户进行选择；修正自动建议模型可以预测出可能是正确翻译结果的翻译选项并建议用户用该翻译选项替换错误翻译。用户对于两个建议模型的建议都可以采用或拒绝。在两个自动建议模型的辅助下，用户的操作进一步被简化，可以进一步提高人机交互效率。实验结果表明，当用户只做一种操作，而让自动建议模型完成另一种操作，只需要很小的交互代价就可以带来较大的翻译质量的提升。
  \item 针对翻译系统的短语调序错误，我们扩展了PR交互翻译框架，引入了限制翻译片段的交互方法。限制翻译片段的交互方法也是一种迭代式的交互方法，该交互方法中，我们要求用户提供限制片段信息，系统利用本文提出的限制解码算法，根据限制片段来进行解码，从而提高翻译质量。实验证明，用户只需要进行很少的交互操作（1.39\% KSMR），且不需要提供正确目标端翻译信息，就可以带来明显的翻译质量的提升（+2.55 BLEU）。
  \item 在PR交互框架的基础上，本文提出了三种基础性的模型自适应的方法，分别是补充翻译模型、翻译模型插值、翻译模型修正方法。在此基础上，将翻译模型插值方法与翻译模型修正方法相结合可以取得更好的自适应效果。模型自适应是迭代更新的过程，不断收集人机交互过程中产生的信息进行自适应。在不断进行人机交互和模型自适应时，翻译系统的翻译能力也能够逐步提高。
\end{enumerate}
\section{未来工作}
现有工作中，仍然存在若干值得继续研究的点，未来工作可以基于这些点进行更深入的研究：
\begin{enumerate}
  \item 在当前的PR交互翻译框架下，我们提出的自动建议模型虽然能够将用户的操作简化成单一操作，目前的性能也达到可接受的程度，但其模型能力仍然有较大提升的空间。我们可以通过更大的数据规模，更多的特征，更优的模型来进一步提升模型能力。
  \item 我们没有进行限制片段翻译方法的大规模实验。未来工作可以让更多的真实用户参与。与PR框架中的自动建议模型类似，限制片段中的自动建议模型的设计和实现也是一个值得研究的方向，另外，基于限制片段的模型自适应的学习也可以在大规模的数据上展开。
  \item 模型自适应方法也是一个值得深入研究的方向。一方面，可以研究提高自适应的效率的方法，做到更快的、实时的模型自适应。另一方面，可以继续研究如何改进当前的模型自适应方法。
\end{enumerate}
% 参考文献。应放在\backmatter之前。
% 推荐使用BibTeX，若不使用BibTeX时注释掉下面一句。
\nocite{*}
\bibliography{sample}
% 不使用 BibTeX
%\begin{thebibliography}{2}
%
%\bibitem{deng:01a}
%{邓建松,彭冉冉,陈长松}.
%\newblock {\em \LaTeXe{}科技排版指南}.
%\newblock 科学出版社,书号:7-03-009239-2/TP.1516, 北京, 2001.
%
%\bibitem{wang:00a}
%王磊.
%\newblock {\em \LaTeXe{}插图指南}.
%\newblock 2000.
%\end{thebibliography}
\begin{acknowledgement}
  时光飞逝，转眼间在南京大学的三年硕士生活即将结束，我也将迎来新的工作和生活。在南京大学计算机科学与技术系以及自然语言处理研究组的三年，我认识了很多优秀的师长和同学，他们给我的工作和生活提供了许多直接帮助，让我受益匪浅，也通过他们自身的勤勉和严谨，给我留下了深刻的印象并树立了良好的榜样，让我间接地感受到了充满活力的学习氛围。

  首先要感谢实验室的陈家俊老师，三年前接收我进入自然语言处理实验室，让我有机会接触到这么多优秀的同学。并且陈老师和蔼可亲、治学严谨，给我在为人处世和学习工作上都带来了深刻的影响。
  
  其次，要感谢我的导师戴新宇老师，戴老师在我的三年研究生期间，一直指导我的工作，给予了我很大的帮助，在生活上也给予了很多关心。此次硕士毕业论文，也是在戴老师的指导下完成的。戴老师提出了很多宝贵的意见，使我能够顺利完成论文的写作。十分感谢戴老师的付出，让我能够走进自然语言处理的世界，使我受益良多。

  同时，也要感谢黄书剑，尹存燕，沈思，李斌，张建兵等实验室的老师们。他们在我的工作中给予了很大的帮助和有价值的建议，使我能够在学习工作中走得更好。特别是感谢李斌老师对本文工作的支持，为我们的实验提供了宝贵的数据，以及在实验过程中提出了很多宝贵的建议。此外，还感谢程川，黄家君，胡光能，牛力强，周逸初，程善伯等几位师兄，给我在学习和工作上提供了很多帮助和建议，让我感受到了实验室作为一个集体，大家相互关心和帮助的氛围，希望你们在今后的人生中越走越好！还要感谢同一级的尚迪，郁振庭，周启元，季红洁，李小婉，王韶杰几位同学，为我提供了很多工作上的帮助。另外，还特别感谢李泽宇、娄超两位师弟，在高考地理试题解答项目中，我们共同合作，互相讨论学习，两位师弟工作认真，十分感谢他们的付出。
  
  最后，我要感谢我的父母，他们给予了对我生活、学习、人生规划上无条件的支持和理解，让我能够选择我喜欢的工作和生活方式，并且在我人生的一路上给予鼓励和关心，让我感觉十分幸运。希望你们可以永远开心、幸福、健康。
   
\end{acknowledgement}
% 附录，必须放在参考文献后，backmatter前
\appendix
%\chapter{测试}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 书籍附件
\backmatter
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 作者简历与科研成果页，应放在backmatter之后
\begin{resume}
%% 论文作者身份简介，一句话即可。
%\begin{authorinfo}
%\noindent 韦小宝，男，汉族，1985年11月出生，江苏省扬州人。
%\end{authorinfo}
%% 论文作者教育经历列表，按日期从近到远排列，不包括将要申请的学位。
%\begin{education}
%\item[20013年9月 --- 2016年6月] 南京大学计算机科学与技术系 \hfill 硕士
%\item[2009年9月 --- 2013年6月] 南京大学计算机科学与技术系 \hfill 本科
%\end{education}
%% 论文作者在攻读学位期间所发表的文章的列表，按发表日期从近到远排列。
\begin{publications}
\item  CHENG S, HUANG S, CHEN H, et al. PRIMT: A Pick-Revise Framework for Interactive Machine Translation[C]//The 15th Annual Conference of the North American Chapter of Association for Computational Linguistics: Human Language Technologies. 2016.
\end{publications}
%\begin{systems}
%\item 交互机器翻译系统中，支持选择-修正交互框架、限制翻译片段交互方法的原型系统。交互翻译系统中的自动建议模型、模型自适应等模块。
%\end{systems}
\begin{patents}
\item 黄书剑, 程善伯, 戴新宇, 陈家骏, 张建兵. 一种计算机中限定翻译片段的交互式翻译方法. 国家发明专利 (已公开). 申请/专利号: 201510330285.X.
\end{patents}
%\begin{projects}
%\item 交互机器翻译系统中，支持选择-修正交互框架、限制翻译片段交互方法的原型系统。交互翻译系统中的自动建议模型、模型自适应等模块。
%\end{projects}
%% 论文作者在攻读学位期间开发的系统。
% 获奖
\begin{awards}
\item 2015 --荣获南京大学二〇一五年“计算机科学与技术系研究生优秀奖学金”
\item 2015 --荣获南京大学二〇一五年“计算机科学与技术系优秀研究生”
\end{awards}
\end{resume}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 生成《学位论文出版授权书》页面，应放在最后一页
\makelicense

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
